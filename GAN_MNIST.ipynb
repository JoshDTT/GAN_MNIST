{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXuUv5JHevXMGkBYNCAN6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshDTT/GAN_MNIST/blob/main/GAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "238k-0zA7KGe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "batch_size = 32\n",
        "learning_rate = 0.0002\n",
        "num_epochs = 100\n",
        "image_size = 28 * 28  # MNIST images are 28x28"
      ],
      "metadata": {
        "id": "a_QmmWXD7pLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones para los datos MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),               #convierte los valores de los píxeles (que van de 0 a 255) a un rango de 0 a 1.\n",
        "    transforms.Normalize((0.5,), (0.5,)) #Esta transformación normaliza los datos para que tengan media 0 y desviación estándar 1,\n",
        "                                         #una vez transformados, los datos irán de -1 a 1, en lugar de 0 a 1\n",
        "                                      ]) #terminamos con un tensor"
      ],
      "metadata": {
        "id": "fe-uTB6V7p-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga del conjunto de datos MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q0gWHMdW7wYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bbe9c51-31b3-4381-ea99-f4eabb8a998f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.27MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 153kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.45MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.81MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de la red generadora\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(256, 256), #añade una capa con 256 neuronas de entrada y 256 de salida\n",
        "            nn.ReLU(True),       #función de activación\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, image_size),\n",
        "            nn.Tanh()  #Se usa Tanh para que la salida esté entre [-1, 1] para mayor estabilidad y eficiencia\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)"
      ],
      "metadata": {
        "id": "BRo21iva71Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de la red discriminante\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(image_size, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),   #en lugar de truncar los negativos los multiplica por 0.2\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()  # Sigmoid para que la salida esté entre [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "UaDFf2MN776L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicialización de las redes\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Definición de las funciones de pérdida y optimizadores\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "5e31PKR-78V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "        # Etiquetas para el discriminante\n",
        "        real_labels = torch.ones(images.size(0), 1)  # Etiquetas para imágenes reales\n",
        "        fake_labels = torch.zeros(images.size(0), 1)  # Etiquetas para imágenes falsas\n",
        "\n",
        "        # Convertir imágenes a vectores\n",
        "        images = images.view(images.size(0), -1)\n",
        "\n",
        "        # Entrenamiento del discriminante\n",
        "        optimizer_D.zero_grad()              # reinicia los gradientes del discriminante para cada iteración\n",
        "        outputs = discriminator(images)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        d_loss_real.backward()               #tomando d_loss_real realiza backpropagation para ajustar los pesos según la pérdida\n",
        "\n",
        "\n",
        "        z = torch.randn(images.size(0), 256)  # Ruido aleatorio para generar imágenes diferentes y no partir siempre del mismo punto\n",
        "        fake_images = generator(z)\n",
        "        outputs = discriminator(fake_images.detach()) #las imágenes falsas se pasan al discriminante para obtener sus predicciones.\n",
        "        d_loss_fake = criterion(outputs, fake_labels) #criterion es la función de pérdida, en este caso BCE\n",
        "        d_loss_fake.backward()\n",
        "\n",
        "        optimizer_D.step()\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        # Entrenamiento del generador\n",
        "        optimizer_G.zero_grad()\n",
        "        outputs = discriminator(fake_images)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], '\n",
        "                  f'D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNzN3C6C79Me",
        "outputId": "cd4c3126-f8a2-42e1-fd7e-5bb8689bb025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Step [100/1875], D Loss: 0.7613, G Loss: 0.9914\n",
            "Epoch [1/100], Step [200/1875], D Loss: 0.5297, G Loss: 0.9679\n",
            "Epoch [1/100], Step [300/1875], D Loss: 0.5367, G Loss: 2.2571\n",
            "Epoch [1/100], Step [400/1875], D Loss: 0.0587, G Loss: 6.1359\n",
            "Epoch [1/100], Step [500/1875], D Loss: 0.0670, G Loss: 5.5127\n",
            "Epoch [1/100], Step [600/1875], D Loss: 0.1610, G Loss: 6.9262\n",
            "Epoch [1/100], Step [700/1875], D Loss: 0.3051, G Loss: 6.1256\n",
            "Epoch [1/100], Step [800/1875], D Loss: 0.0128, G Loss: 6.3781\n",
            "Epoch [1/100], Step [900/1875], D Loss: 0.0136, G Loss: 6.8400\n",
            "Epoch [1/100], Step [1000/1875], D Loss: 0.1742, G Loss: 9.3117\n",
            "Epoch [1/100], Step [1100/1875], D Loss: 0.0117, G Loss: 8.3049\n",
            "Epoch [1/100], Step [1200/1875], D Loss: 0.1633, G Loss: 7.9205\n",
            "Epoch [1/100], Step [1300/1875], D Loss: 0.0486, G Loss: 6.9481\n",
            "Epoch [1/100], Step [1400/1875], D Loss: 0.0706, G Loss: 9.9912\n",
            "Epoch [1/100], Step [1500/1875], D Loss: 0.2757, G Loss: 7.4868\n",
            "Epoch [1/100], Step [1600/1875], D Loss: 0.2986, G Loss: 7.4402\n",
            "Epoch [1/100], Step [1700/1875], D Loss: 0.4185, G Loss: 10.5066\n",
            "Epoch [1/100], Step [1800/1875], D Loss: 0.3977, G Loss: 4.6450\n",
            "Epoch [2/100], Step [100/1875], D Loss: 0.5289, G Loss: 4.5152\n",
            "Epoch [2/100], Step [200/1875], D Loss: 1.3666, G Loss: 3.0239\n",
            "Epoch [2/100], Step [300/1875], D Loss: 0.9735, G Loss: 2.1177\n",
            "Epoch [2/100], Step [400/1875], D Loss: 0.8399, G Loss: 2.0493\n",
            "Epoch [2/100], Step [500/1875], D Loss: 2.4926, G Loss: 0.9603\n",
            "Epoch [2/100], Step [600/1875], D Loss: 0.5004, G Loss: 2.4836\n",
            "Epoch [2/100], Step [700/1875], D Loss: 0.7529, G Loss: 2.8787\n",
            "Epoch [2/100], Step [800/1875], D Loss: 0.8654, G Loss: 2.2636\n",
            "Epoch [2/100], Step [900/1875], D Loss: 1.4242, G Loss: 2.0680\n",
            "Epoch [2/100], Step [1000/1875], D Loss: 0.5794, G Loss: 1.7898\n",
            "Epoch [2/100], Step [1100/1875], D Loss: 0.8584, G Loss: 1.7887\n",
            "Epoch [2/100], Step [1200/1875], D Loss: 0.4547, G Loss: 2.9993\n",
            "Epoch [2/100], Step [1300/1875], D Loss: 0.3986, G Loss: 3.1981\n",
            "Epoch [2/100], Step [1400/1875], D Loss: 0.3362, G Loss: 2.6221\n",
            "Epoch [2/100], Step [1500/1875], D Loss: 0.7840, G Loss: 2.1010\n",
            "Epoch [2/100], Step [1600/1875], D Loss: 0.7630, G Loss: 2.2832\n",
            "Epoch [2/100], Step [1700/1875], D Loss: 1.0112, G Loss: 2.6519\n",
            "Epoch [2/100], Step [1800/1875], D Loss: 0.5950, G Loss: 3.6535\n",
            "Epoch [3/100], Step [100/1875], D Loss: 0.4846, G Loss: 2.2766\n",
            "Epoch [3/100], Step [200/1875], D Loss: 0.4851, G Loss: 2.8848\n",
            "Epoch [3/100], Step [300/1875], D Loss: 0.5541, G Loss: 3.0552\n",
            "Epoch [3/100], Step [400/1875], D Loss: 0.4998, G Loss: 1.6799\n",
            "Epoch [3/100], Step [500/1875], D Loss: 0.2643, G Loss: 3.0257\n",
            "Epoch [3/100], Step [600/1875], D Loss: 0.4709, G Loss: 4.8605\n",
            "Epoch [3/100], Step [700/1875], D Loss: 1.1945, G Loss: 6.1926\n",
            "Epoch [3/100], Step [800/1875], D Loss: 0.4551, G Loss: 4.7785\n",
            "Epoch [3/100], Step [900/1875], D Loss: 0.0858, G Loss: 5.6793\n",
            "Epoch [3/100], Step [1000/1875], D Loss: 0.1606, G Loss: 6.5792\n",
            "Epoch [3/100], Step [1100/1875], D Loss: 0.3807, G Loss: 3.2887\n",
            "Epoch [3/100], Step [1200/1875], D Loss: 0.6339, G Loss: 2.9818\n",
            "Epoch [3/100], Step [1300/1875], D Loss: 0.5498, G Loss: 3.1293\n",
            "Epoch [3/100], Step [1400/1875], D Loss: 0.3182, G Loss: 3.4833\n",
            "Epoch [3/100], Step [1500/1875], D Loss: 0.2427, G Loss: 4.5020\n",
            "Epoch [3/100], Step [1600/1875], D Loss: 0.9985, G Loss: 4.4791\n",
            "Epoch [3/100], Step [1700/1875], D Loss: 0.4682, G Loss: 3.7009\n",
            "Epoch [3/100], Step [1800/1875], D Loss: 0.5928, G Loss: 2.5674\n",
            "Epoch [4/100], Step [100/1875], D Loss: 0.4583, G Loss: 4.1010\n",
            "Epoch [4/100], Step [200/1875], D Loss: 0.1369, G Loss: 4.0715\n",
            "Epoch [4/100], Step [300/1875], D Loss: 0.1123, G Loss: 3.4525\n",
            "Epoch [4/100], Step [400/1875], D Loss: 0.2574, G Loss: 5.1915\n",
            "Epoch [4/100], Step [500/1875], D Loss: 0.9249, G Loss: 1.8977\n",
            "Epoch [4/100], Step [600/1875], D Loss: 0.4745, G Loss: 3.5952\n",
            "Epoch [4/100], Step [700/1875], D Loss: 0.7721, G Loss: 3.4453\n",
            "Epoch [4/100], Step [800/1875], D Loss: 0.3366, G Loss: 3.3477\n",
            "Epoch [4/100], Step [900/1875], D Loss: 0.5037, G Loss: 2.9825\n",
            "Epoch [4/100], Step [1000/1875], D Loss: 0.3567, G Loss: 4.1076\n",
            "Epoch [4/100], Step [1100/1875], D Loss: 0.1435, G Loss: 4.7425\n",
            "Epoch [4/100], Step [1200/1875], D Loss: 1.2633, G Loss: 3.1100\n",
            "Epoch [4/100], Step [1300/1875], D Loss: 0.2855, G Loss: 2.3703\n",
            "Epoch [4/100], Step [1400/1875], D Loss: 0.6241, G Loss: 3.1492\n",
            "Epoch [4/100], Step [1500/1875], D Loss: 0.4208, G Loss: 3.5498\n",
            "Epoch [4/100], Step [1600/1875], D Loss: 0.5883, G Loss: 3.9527\n",
            "Epoch [4/100], Step [1700/1875], D Loss: 0.2558, G Loss: 4.4799\n",
            "Epoch [4/100], Step [1800/1875], D Loss: 0.8632, G Loss: 3.8764\n",
            "Epoch [5/100], Step [100/1875], D Loss: 0.8769, G Loss: 4.7260\n",
            "Epoch [5/100], Step [200/1875], D Loss: 0.6212, G Loss: 2.6313\n",
            "Epoch [5/100], Step [300/1875], D Loss: 0.3265, G Loss: 3.8113\n",
            "Epoch [5/100], Step [400/1875], D Loss: 0.7917, G Loss: 3.2127\n",
            "Epoch [5/100], Step [500/1875], D Loss: 0.4407, G Loss: 2.3744\n",
            "Epoch [5/100], Step [600/1875], D Loss: 0.4780, G Loss: 3.9219\n",
            "Epoch [5/100], Step [700/1875], D Loss: 1.0626, G Loss: 2.3397\n",
            "Epoch [5/100], Step [800/1875], D Loss: 0.4477, G Loss: 2.8884\n",
            "Epoch [5/100], Step [900/1875], D Loss: 0.6056, G Loss: 2.7985\n",
            "Epoch [5/100], Step [1000/1875], D Loss: 0.3206, G Loss: 3.1220\n",
            "Epoch [5/100], Step [1100/1875], D Loss: 0.2429, G Loss: 4.1503\n",
            "Epoch [5/100], Step [1200/1875], D Loss: 0.3643, G Loss: 2.4257\n",
            "Epoch [5/100], Step [1300/1875], D Loss: 0.2760, G Loss: 4.0054\n",
            "Epoch [5/100], Step [1400/1875], D Loss: 0.4353, G Loss: 2.8649\n",
            "Epoch [5/100], Step [1500/1875], D Loss: 0.3878, G Loss: 1.9760\n",
            "Epoch [5/100], Step [1600/1875], D Loss: 0.4097, G Loss: 3.0045\n",
            "Epoch [5/100], Step [1700/1875], D Loss: 0.3830, G Loss: 3.0797\n",
            "Epoch [5/100], Step [1800/1875], D Loss: 0.5027, G Loss: 3.0328\n",
            "Epoch [6/100], Step [100/1875], D Loss: 0.5258, G Loss: 2.8160\n",
            "Epoch [6/100], Step [200/1875], D Loss: 0.4649, G Loss: 2.8666\n",
            "Epoch [6/100], Step [300/1875], D Loss: 0.2365, G Loss: 3.8536\n",
            "Epoch [6/100], Step [400/1875], D Loss: 1.1599, G Loss: 2.9975\n",
            "Epoch [6/100], Step [500/1875], D Loss: 0.8328, G Loss: 3.4229\n",
            "Epoch [6/100], Step [600/1875], D Loss: 1.1577, G Loss: 2.1079\n",
            "Epoch [6/100], Step [700/1875], D Loss: 0.3411, G Loss: 3.7656\n",
            "Epoch [6/100], Step [800/1875], D Loss: 0.2217, G Loss: 3.3833\n",
            "Epoch [6/100], Step [900/1875], D Loss: 0.4675, G Loss: 2.6410\n",
            "Epoch [6/100], Step [1000/1875], D Loss: 0.7125, G Loss: 2.2823\n",
            "Epoch [6/100], Step [1100/1875], D Loss: 0.8201, G Loss: 5.9417\n",
            "Epoch [6/100], Step [1200/1875], D Loss: 0.5435, G Loss: 5.5460\n",
            "Epoch [6/100], Step [1300/1875], D Loss: 0.2833, G Loss: 4.4502\n",
            "Epoch [6/100], Step [1400/1875], D Loss: 0.3427, G Loss: 3.8394\n",
            "Epoch [6/100], Step [1500/1875], D Loss: 0.7614, G Loss: 4.4937\n",
            "Epoch [6/100], Step [1600/1875], D Loss: 0.3618, G Loss: 3.4593\n",
            "Epoch [6/100], Step [1700/1875], D Loss: 0.8527, G Loss: 5.7721\n",
            "Epoch [6/100], Step [1800/1875], D Loss: 0.3336, G Loss: 3.9420\n",
            "Epoch [7/100], Step [100/1875], D Loss: 0.7849, G Loss: 3.4174\n",
            "Epoch [7/100], Step [200/1875], D Loss: 0.3261, G Loss: 3.7042\n",
            "Epoch [7/100], Step [300/1875], D Loss: 0.2345, G Loss: 3.8308\n",
            "Epoch [7/100], Step [400/1875], D Loss: 0.2919, G Loss: 4.1308\n",
            "Epoch [7/100], Step [500/1875], D Loss: 0.5846, G Loss: 2.9137\n",
            "Epoch [7/100], Step [600/1875], D Loss: 0.3410, G Loss: 3.7727\n",
            "Epoch [7/100], Step [700/1875], D Loss: 0.1799, G Loss: 4.7747\n",
            "Epoch [7/100], Step [800/1875], D Loss: 0.6652, G Loss: 2.4276\n",
            "Epoch [7/100], Step [900/1875], D Loss: 0.1034, G Loss: 3.5880\n",
            "Epoch [7/100], Step [1000/1875], D Loss: 0.5833, G Loss: 3.5499\n",
            "Epoch [7/100], Step [1100/1875], D Loss: 0.4332, G Loss: 4.5000\n",
            "Epoch [7/100], Step [1200/1875], D Loss: 0.2342, G Loss: 3.6242\n",
            "Epoch [7/100], Step [1300/1875], D Loss: 0.3214, G Loss: 2.6233\n",
            "Epoch [7/100], Step [1400/1875], D Loss: 0.2711, G Loss: 5.1494\n",
            "Epoch [7/100], Step [1500/1875], D Loss: 0.3805, G Loss: 5.0451\n",
            "Epoch [7/100], Step [1600/1875], D Loss: 0.3894, G Loss: 5.0121\n",
            "Epoch [7/100], Step [1700/1875], D Loss: 0.1339, G Loss: 6.0989\n",
            "Epoch [7/100], Step [1800/1875], D Loss: 0.3745, G Loss: 3.8011\n",
            "Epoch [8/100], Step [100/1875], D Loss: 0.1523, G Loss: 5.7832\n",
            "Epoch [8/100], Step [200/1875], D Loss: 1.0718, G Loss: 3.6851\n",
            "Epoch [8/100], Step [300/1875], D Loss: 0.0527, G Loss: 5.7466\n",
            "Epoch [8/100], Step [400/1875], D Loss: 0.2879, G Loss: 5.2356\n",
            "Epoch [8/100], Step [500/1875], D Loss: 0.4969, G Loss: 3.4975\n",
            "Epoch [8/100], Step [600/1875], D Loss: 0.1602, G Loss: 4.2410\n",
            "Epoch [8/100], Step [700/1875], D Loss: 0.4150, G Loss: 5.2462\n",
            "Epoch [8/100], Step [800/1875], D Loss: 0.5773, G Loss: 3.9197\n",
            "Epoch [8/100], Step [900/1875], D Loss: 0.7695, G Loss: 2.1690\n",
            "Epoch [8/100], Step [1000/1875], D Loss: 0.3904, G Loss: 2.4544\n",
            "Epoch [8/100], Step [1100/1875], D Loss: 0.3558, G Loss: 3.4720\n",
            "Epoch [8/100], Step [1200/1875], D Loss: 0.4928, G Loss: 3.7744\n",
            "Epoch [8/100], Step [1300/1875], D Loss: 0.7473, G Loss: 2.7821\n",
            "Epoch [8/100], Step [1400/1875], D Loss: 0.1268, G Loss: 3.9960\n",
            "Epoch [8/100], Step [1500/1875], D Loss: 0.3233, G Loss: 4.6756\n",
            "Epoch [8/100], Step [1600/1875], D Loss: 0.4307, G Loss: 4.2484\n",
            "Epoch [8/100], Step [1700/1875], D Loss: 0.7921, G Loss: 3.0124\n",
            "Epoch [8/100], Step [1800/1875], D Loss: 0.2503, G Loss: 3.5969\n",
            "Epoch [9/100], Step [100/1875], D Loss: 0.2646, G Loss: 5.2113\n",
            "Epoch [9/100], Step [200/1875], D Loss: 0.8186, G Loss: 4.4481\n",
            "Epoch [9/100], Step [300/1875], D Loss: 0.3582, G Loss: 3.1822\n",
            "Epoch [9/100], Step [400/1875], D Loss: 0.2517, G Loss: 4.1305\n",
            "Epoch [9/100], Step [500/1875], D Loss: 0.3082, G Loss: 3.5760\n",
            "Epoch [9/100], Step [600/1875], D Loss: 0.2834, G Loss: 3.7857\n",
            "Epoch [9/100], Step [700/1875], D Loss: 0.1183, G Loss: 5.3596\n",
            "Epoch [9/100], Step [800/1875], D Loss: 0.0709, G Loss: 5.4310\n",
            "Epoch [9/100], Step [900/1875], D Loss: 0.4142, G Loss: 3.7437\n",
            "Epoch [9/100], Step [1000/1875], D Loss: 0.1283, G Loss: 6.2129\n",
            "Epoch [9/100], Step [1100/1875], D Loss: 0.8405, G Loss: 5.4303\n",
            "Epoch [9/100], Step [1200/1875], D Loss: 0.1532, G Loss: 4.4578\n",
            "Epoch [9/100], Step [1300/1875], D Loss: 0.0891, G Loss: 5.3526\n",
            "Epoch [9/100], Step [1400/1875], D Loss: 0.3501, G Loss: 4.3611\n",
            "Epoch [9/100], Step [1500/1875], D Loss: 0.6118, G Loss: 3.9908\n",
            "Epoch [9/100], Step [1600/1875], D Loss: 0.1571, G Loss: 7.4572\n",
            "Epoch [9/100], Step [1700/1875], D Loss: 0.2737, G Loss: 3.1305\n",
            "Epoch [9/100], Step [1800/1875], D Loss: 0.6265, G Loss: 2.7977\n",
            "Epoch [10/100], Step [100/1875], D Loss: 0.1625, G Loss: 3.5463\n",
            "Epoch [10/100], Step [200/1875], D Loss: 0.1132, G Loss: 3.8537\n",
            "Epoch [10/100], Step [300/1875], D Loss: 0.2084, G Loss: 3.1534\n",
            "Epoch [10/100], Step [400/1875], D Loss: 0.5591, G Loss: 2.8656\n",
            "Epoch [10/100], Step [500/1875], D Loss: 0.0564, G Loss: 4.7158\n",
            "Epoch [10/100], Step [600/1875], D Loss: 0.2288, G Loss: 5.0267\n",
            "Epoch [10/100], Step [700/1875], D Loss: 0.2895, G Loss: 3.2349\n",
            "Epoch [10/100], Step [800/1875], D Loss: 0.2218, G Loss: 5.9958\n",
            "Epoch [10/100], Step [900/1875], D Loss: 0.3805, G Loss: 4.7684\n",
            "Epoch [10/100], Step [1000/1875], D Loss: 0.6348, G Loss: 5.1963\n",
            "Epoch [10/100], Step [1100/1875], D Loss: 0.4333, G Loss: 4.4195\n",
            "Epoch [10/100], Step [1200/1875], D Loss: 0.5470, G Loss: 3.7090\n",
            "Epoch [10/100], Step [1300/1875], D Loss: 0.2297, G Loss: 3.6347\n",
            "Epoch [10/100], Step [1400/1875], D Loss: 0.4177, G Loss: 3.6636\n",
            "Epoch [10/100], Step [1500/1875], D Loss: 0.1688, G Loss: 5.4496\n",
            "Epoch [10/100], Step [1600/1875], D Loss: 0.1596, G Loss: 3.2072\n",
            "Epoch [10/100], Step [1700/1875], D Loss: 0.0588, G Loss: 5.6659\n",
            "Epoch [10/100], Step [1800/1875], D Loss: 0.1448, G Loss: 4.0713\n",
            "Epoch [11/100], Step [100/1875], D Loss: 0.2956, G Loss: 3.1404\n",
            "Epoch [11/100], Step [200/1875], D Loss: 0.1062, G Loss: 4.1288\n",
            "Epoch [11/100], Step [300/1875], D Loss: 0.2246, G Loss: 5.5262\n",
            "Epoch [11/100], Step [400/1875], D Loss: 0.2371, G Loss: 3.3819\n",
            "Epoch [11/100], Step [500/1875], D Loss: 0.3685, G Loss: 3.9198\n",
            "Epoch [11/100], Step [600/1875], D Loss: 0.4609, G Loss: 3.9142\n",
            "Epoch [11/100], Step [700/1875], D Loss: 0.0546, G Loss: 6.8342\n",
            "Epoch [11/100], Step [800/1875], D Loss: 0.0190, G Loss: 6.1081\n",
            "Epoch [11/100], Step [900/1875], D Loss: 0.1072, G Loss: 4.8501\n",
            "Epoch [11/100], Step [1000/1875], D Loss: 0.2028, G Loss: 5.5105\n",
            "Epoch [11/100], Step [1100/1875], D Loss: 0.2373, G Loss: 6.3918\n",
            "Epoch [11/100], Step [1200/1875], D Loss: 0.1929, G Loss: 4.1522\n",
            "Epoch [11/100], Step [1300/1875], D Loss: 0.2060, G Loss: 4.7810\n",
            "Epoch [11/100], Step [1400/1875], D Loss: 0.1941, G Loss: 4.0953\n",
            "Epoch [11/100], Step [1500/1875], D Loss: 1.9671, G Loss: 8.4548\n",
            "Epoch [11/100], Step [1600/1875], D Loss: 0.5425, G Loss: 3.2894\n",
            "Epoch [11/100], Step [1700/1875], D Loss: 0.0746, G Loss: 5.4910\n",
            "Epoch [11/100], Step [1800/1875], D Loss: 0.0793, G Loss: 4.5275\n",
            "Epoch [12/100], Step [100/1875], D Loss: 0.2218, G Loss: 4.2425\n",
            "Epoch [12/100], Step [200/1875], D Loss: 0.1401, G Loss: 5.2606\n",
            "Epoch [12/100], Step [300/1875], D Loss: 0.1466, G Loss: 4.0273\n",
            "Epoch [12/100], Step [400/1875], D Loss: 0.0856, G Loss: 5.9801\n",
            "Epoch [12/100], Step [500/1875], D Loss: 0.4579, G Loss: 2.9840\n",
            "Epoch [12/100], Step [600/1875], D Loss: 0.5410, G Loss: 2.8445\n",
            "Epoch [12/100], Step [700/1875], D Loss: 0.2869, G Loss: 3.6563\n",
            "Epoch [12/100], Step [800/1875], D Loss: 0.0820, G Loss: 4.5445\n",
            "Epoch [12/100], Step [900/1875], D Loss: 0.1069, G Loss: 5.3745\n",
            "Epoch [12/100], Step [1000/1875], D Loss: 0.3325, G Loss: 4.5565\n",
            "Epoch [12/100], Step [1100/1875], D Loss: 0.1342, G Loss: 5.6740\n",
            "Epoch [12/100], Step [1200/1875], D Loss: 0.1376, G Loss: 3.7382\n",
            "Epoch [12/100], Step [1300/1875], D Loss: 0.3234, G Loss: 3.8978\n",
            "Epoch [12/100], Step [1400/1875], D Loss: 0.2411, G Loss: 3.4213\n",
            "Epoch [12/100], Step [1500/1875], D Loss: 0.1312, G Loss: 4.3031\n",
            "Epoch [12/100], Step [1600/1875], D Loss: 0.1340, G Loss: 3.9962\n",
            "Epoch [12/100], Step [1700/1875], D Loss: 0.2135, G Loss: 5.6976\n",
            "Epoch [12/100], Step [1800/1875], D Loss: 0.2894, G Loss: 4.8639\n",
            "Epoch [13/100], Step [100/1875], D Loss: 0.1334, G Loss: 6.0929\n",
            "Epoch [13/100], Step [200/1875], D Loss: 0.3777, G Loss: 3.7877\n",
            "Epoch [13/100], Step [300/1875], D Loss: 0.0399, G Loss: 4.7768\n",
            "Epoch [13/100], Step [400/1875], D Loss: 0.1263, G Loss: 4.8122\n",
            "Epoch [13/100], Step [500/1875], D Loss: 0.1307, G Loss: 5.5032\n",
            "Epoch [13/100], Step [600/1875], D Loss: 0.4399, G Loss: 2.9702\n",
            "Epoch [13/100], Step [700/1875], D Loss: 0.0826, G Loss: 5.3553\n",
            "Epoch [13/100], Step [800/1875], D Loss: 0.0790, G Loss: 5.5637\n",
            "Epoch [13/100], Step [900/1875], D Loss: 0.1934, G Loss: 7.2124\n",
            "Epoch [13/100], Step [1000/1875], D Loss: 0.2844, G Loss: 3.3411\n",
            "Epoch [13/100], Step [1100/1875], D Loss: 0.5762, G Loss: 6.2422\n",
            "Epoch [13/100], Step [1200/1875], D Loss: 0.8909, G Loss: 4.5529\n",
            "Epoch [13/100], Step [1300/1875], D Loss: 0.1303, G Loss: 5.1863\n",
            "Epoch [13/100], Step [1400/1875], D Loss: 0.4838, G Loss: 6.0748\n",
            "Epoch [13/100], Step [1500/1875], D Loss: 0.0557, G Loss: 3.7781\n",
            "Epoch [13/100], Step [1600/1875], D Loss: 0.6471, G Loss: 3.9420\n",
            "Epoch [13/100], Step [1700/1875], D Loss: 0.1111, G Loss: 6.7408\n",
            "Epoch [13/100], Step [1800/1875], D Loss: 0.1164, G Loss: 4.9188\n",
            "Epoch [14/100], Step [100/1875], D Loss: 0.1808, G Loss: 4.1657\n",
            "Epoch [14/100], Step [200/1875], D Loss: 0.1433, G Loss: 4.0145\n",
            "Epoch [14/100], Step [300/1875], D Loss: 0.2763, G Loss: 2.5598\n",
            "Epoch [14/100], Step [400/1875], D Loss: 0.3235, G Loss: 4.9070\n",
            "Epoch [14/100], Step [500/1875], D Loss: 0.4263, G Loss: 2.4233\n",
            "Epoch [14/100], Step [600/1875], D Loss: 0.7619, G Loss: 4.8200\n",
            "Epoch [14/100], Step [700/1875], D Loss: 0.3548, G Loss: 5.1727\n",
            "Epoch [14/100], Step [800/1875], D Loss: 0.5325, G Loss: 4.9673\n",
            "Epoch [14/100], Step [900/1875], D Loss: 0.2127, G Loss: 3.4135\n",
            "Epoch [14/100], Step [1000/1875], D Loss: 0.4204, G Loss: 3.2798\n",
            "Epoch [14/100], Step [1100/1875], D Loss: 0.2254, G Loss: 2.6274\n",
            "Epoch [14/100], Step [1200/1875], D Loss: 0.2566, G Loss: 4.1186\n",
            "Epoch [14/100], Step [1300/1875], D Loss: 0.4655, G Loss: 4.5965\n",
            "Epoch [14/100], Step [1400/1875], D Loss: 0.4383, G Loss: 3.4213\n",
            "Epoch [14/100], Step [1500/1875], D Loss: 0.2164, G Loss: 3.9339\n",
            "Epoch [14/100], Step [1600/1875], D Loss: 0.3333, G Loss: 3.5633\n",
            "Epoch [14/100], Step [1700/1875], D Loss: 0.4945, G Loss: 3.9410\n",
            "Epoch [14/100], Step [1800/1875], D Loss: 0.2792, G Loss: 5.9322\n",
            "Epoch [15/100], Step [100/1875], D Loss: 0.1769, G Loss: 4.2034\n",
            "Epoch [15/100], Step [200/1875], D Loss: 0.3804, G Loss: 2.5187\n",
            "Epoch [15/100], Step [300/1875], D Loss: 0.1511, G Loss: 3.8433\n",
            "Epoch [15/100], Step [400/1875], D Loss: 0.7546, G Loss: 3.0907\n",
            "Epoch [15/100], Step [500/1875], D Loss: 0.4270, G Loss: 4.1454\n",
            "Epoch [15/100], Step [600/1875], D Loss: 0.4502, G Loss: 3.3232\n",
            "Epoch [15/100], Step [700/1875], D Loss: 0.3833, G Loss: 2.7215\n",
            "Epoch [15/100], Step [800/1875], D Loss: 0.4393, G Loss: 3.0534\n",
            "Epoch [15/100], Step [900/1875], D Loss: 0.4395, G Loss: 3.0266\n",
            "Epoch [15/100], Step [1000/1875], D Loss: 0.3205, G Loss: 2.8332\n",
            "Epoch [15/100], Step [1100/1875], D Loss: 0.4606, G Loss: 3.5865\n",
            "Epoch [15/100], Step [1200/1875], D Loss: 0.1987, G Loss: 3.2591\n",
            "Epoch [15/100], Step [1300/1875], D Loss: 0.1400, G Loss: 4.3562\n",
            "Epoch [15/100], Step [1400/1875], D Loss: 0.3374, G Loss: 2.1507\n",
            "Epoch [15/100], Step [1500/1875], D Loss: 0.2287, G Loss: 2.3184\n",
            "Epoch [15/100], Step [1600/1875], D Loss: 0.3770, G Loss: 3.0015\n",
            "Epoch [15/100], Step [1700/1875], D Loss: 0.5884, G Loss: 3.4273\n",
            "Epoch [15/100], Step [1800/1875], D Loss: 0.1641, G Loss: 3.3727\n",
            "Epoch [16/100], Step [100/1875], D Loss: 0.5654, G Loss: 3.0902\n",
            "Epoch [16/100], Step [200/1875], D Loss: 0.4009, G Loss: 3.4958\n",
            "Epoch [16/100], Step [300/1875], D Loss: 1.0315, G Loss: 2.7796\n",
            "Epoch [16/100], Step [400/1875], D Loss: 0.3005, G Loss: 2.8014\n",
            "Epoch [16/100], Step [500/1875], D Loss: 0.3555, G Loss: 5.1658\n",
            "Epoch [16/100], Step [600/1875], D Loss: 0.4821, G Loss: 2.6894\n",
            "Epoch [16/100], Step [700/1875], D Loss: 0.3514, G Loss: 3.3896\n",
            "Epoch [16/100], Step [800/1875], D Loss: 0.4368, G Loss: 2.7266\n",
            "Epoch [16/100], Step [900/1875], D Loss: 0.2239, G Loss: 5.0487\n",
            "Epoch [16/100], Step [1000/1875], D Loss: 0.4933, G Loss: 2.9476\n",
            "Epoch [16/100], Step [1100/1875], D Loss: 0.3830, G Loss: 4.5296\n",
            "Epoch [16/100], Step [1200/1875], D Loss: 0.8477, G Loss: 5.4624\n",
            "Epoch [16/100], Step [1300/1875], D Loss: 0.3633, G Loss: 3.3006\n",
            "Epoch [16/100], Step [1400/1875], D Loss: 0.4138, G Loss: 3.4442\n",
            "Epoch [16/100], Step [1500/1875], D Loss: 0.5059, G Loss: 3.2184\n",
            "Epoch [16/100], Step [1600/1875], D Loss: 0.5966, G Loss: 2.2359\n",
            "Epoch [16/100], Step [1700/1875], D Loss: 0.5930, G Loss: 4.8345\n",
            "Epoch [16/100], Step [1800/1875], D Loss: 0.4442, G Loss: 3.9190\n",
            "Epoch [17/100], Step [100/1875], D Loss: 0.3923, G Loss: 2.7175\n",
            "Epoch [17/100], Step [200/1875], D Loss: 0.5534, G Loss: 2.7487\n",
            "Epoch [17/100], Step [300/1875], D Loss: 0.8562, G Loss: 1.8282\n",
            "Epoch [17/100], Step [400/1875], D Loss: 0.8820, G Loss: 2.8531\n",
            "Epoch [17/100], Step [500/1875], D Loss: 0.6986, G Loss: 2.3453\n",
            "Epoch [17/100], Step [600/1875], D Loss: 0.4803, G Loss: 1.8695\n",
            "Epoch [17/100], Step [700/1875], D Loss: 0.4698, G Loss: 2.8287\n",
            "Epoch [17/100], Step [800/1875], D Loss: 0.7228, G Loss: 1.9084\n",
            "Epoch [17/100], Step [900/1875], D Loss: 0.5803, G Loss: 3.8896\n",
            "Epoch [17/100], Step [1000/1875], D Loss: 0.4702, G Loss: 3.6321\n",
            "Epoch [17/100], Step [1100/1875], D Loss: 0.3971, G Loss: 4.3576\n",
            "Epoch [17/100], Step [1200/1875], D Loss: 0.5703, G Loss: 3.1887\n",
            "Epoch [17/100], Step [1300/1875], D Loss: 0.6587, G Loss: 2.4308\n",
            "Epoch [17/100], Step [1400/1875], D Loss: 0.6163, G Loss: 2.8322\n",
            "Epoch [17/100], Step [1500/1875], D Loss: 0.4554, G Loss: 2.9774\n",
            "Epoch [17/100], Step [1600/1875], D Loss: 0.4747, G Loss: 2.7379\n",
            "Epoch [17/100], Step [1700/1875], D Loss: 0.4290, G Loss: 2.1114\n",
            "Epoch [17/100], Step [1800/1875], D Loss: 0.6906, G Loss: 2.5024\n",
            "Epoch [18/100], Step [100/1875], D Loss: 0.3539, G Loss: 2.6803\n",
            "Epoch [18/100], Step [200/1875], D Loss: 0.6883, G Loss: 2.3253\n",
            "Epoch [18/100], Step [300/1875], D Loss: 0.6564, G Loss: 2.3252\n",
            "Epoch [18/100], Step [400/1875], D Loss: 0.5804, G Loss: 2.8178\n",
            "Epoch [18/100], Step [500/1875], D Loss: 0.4910, G Loss: 2.6592\n",
            "Epoch [18/100], Step [600/1875], D Loss: 0.6338, G Loss: 2.5847\n",
            "Epoch [18/100], Step [700/1875], D Loss: 0.5137, G Loss: 2.3628\n",
            "Epoch [18/100], Step [800/1875], D Loss: 0.6033, G Loss: 2.6624\n",
            "Epoch [18/100], Step [900/1875], D Loss: 0.6110, G Loss: 3.0584\n",
            "Epoch [18/100], Step [1000/1875], D Loss: 0.3931, G Loss: 3.0681\n",
            "Epoch [18/100], Step [1100/1875], D Loss: 0.3351, G Loss: 3.3238\n",
            "Epoch [18/100], Step [1200/1875], D Loss: 0.4309, G Loss: 2.4569\n",
            "Epoch [18/100], Step [1300/1875], D Loss: 0.6173, G Loss: 2.7479\n",
            "Epoch [18/100], Step [1400/1875], D Loss: 0.7563, G Loss: 3.1570\n",
            "Epoch [18/100], Step [1500/1875], D Loss: 0.6171, G Loss: 2.1464\n",
            "Epoch [18/100], Step [1600/1875], D Loss: 0.5902, G Loss: 2.5906\n",
            "Epoch [18/100], Step [1700/1875], D Loss: 0.4047, G Loss: 2.0675\n",
            "Epoch [18/100], Step [1800/1875], D Loss: 0.9616, G Loss: 1.9901\n",
            "Epoch [19/100], Step [100/1875], D Loss: 0.4580, G Loss: 2.2784\n",
            "Epoch [19/100], Step [200/1875], D Loss: 0.5848, G Loss: 3.3834\n",
            "Epoch [19/100], Step [300/1875], D Loss: 0.5782, G Loss: 3.0608\n",
            "Epoch [19/100], Step [400/1875], D Loss: 0.6516, G Loss: 2.2661\n",
            "Epoch [19/100], Step [500/1875], D Loss: 0.4090, G Loss: 2.7920\n",
            "Epoch [19/100], Step [600/1875], D Loss: 0.5233, G Loss: 2.7070\n",
            "Epoch [19/100], Step [700/1875], D Loss: 0.6635, G Loss: 2.4189\n",
            "Epoch [19/100], Step [800/1875], D Loss: 0.6258, G Loss: 2.6127\n",
            "Epoch [19/100], Step [900/1875], D Loss: 0.4100, G Loss: 3.1802\n",
            "Epoch [19/100], Step [1000/1875], D Loss: 0.7600, G Loss: 2.7638\n",
            "Epoch [19/100], Step [1100/1875], D Loss: 0.7350, G Loss: 1.9447\n",
            "Epoch [19/100], Step [1200/1875], D Loss: 0.5672, G Loss: 2.1950\n",
            "Epoch [19/100], Step [1300/1875], D Loss: 0.4088, G Loss: 3.2689\n",
            "Epoch [19/100], Step [1400/1875], D Loss: 0.5566, G Loss: 3.6853\n",
            "Epoch [19/100], Step [1500/1875], D Loss: 0.4825, G Loss: 2.6181\n",
            "Epoch [19/100], Step [1600/1875], D Loss: 0.6858, G Loss: 2.9967\n",
            "Epoch [19/100], Step [1700/1875], D Loss: 0.5553, G Loss: 2.9158\n",
            "Epoch [19/100], Step [1800/1875], D Loss: 0.7725, G Loss: 3.6357\n",
            "Epoch [20/100], Step [100/1875], D Loss: 0.3153, G Loss: 3.4289\n",
            "Epoch [20/100], Step [200/1875], D Loss: 0.8194, G Loss: 2.2859\n",
            "Epoch [20/100], Step [300/1875], D Loss: 0.5568, G Loss: 2.0408\n",
            "Epoch [20/100], Step [400/1875], D Loss: 0.6163, G Loss: 3.0330\n",
            "Epoch [20/100], Step [500/1875], D Loss: 0.4048, G Loss: 3.1091\n",
            "Epoch [20/100], Step [600/1875], D Loss: 0.3283, G Loss: 3.0220\n",
            "Epoch [20/100], Step [700/1875], D Loss: 0.6574, G Loss: 2.3129\n",
            "Epoch [20/100], Step [800/1875], D Loss: 0.4834, G Loss: 2.9535\n",
            "Epoch [20/100], Step [900/1875], D Loss: 0.8116, G Loss: 2.5038\n",
            "Epoch [20/100], Step [1000/1875], D Loss: 0.5708, G Loss: 2.4504\n",
            "Epoch [20/100], Step [1100/1875], D Loss: 0.4036, G Loss: 2.5339\n",
            "Epoch [20/100], Step [1200/1875], D Loss: 0.7447, G Loss: 2.1596\n",
            "Epoch [20/100], Step [1300/1875], D Loss: 0.7069, G Loss: 1.9646\n",
            "Epoch [20/100], Step [1400/1875], D Loss: 0.7214, G Loss: 1.8302\n",
            "Epoch [20/100], Step [1500/1875], D Loss: 0.7548, G Loss: 2.5666\n",
            "Epoch [20/100], Step [1600/1875], D Loss: 0.6929, G Loss: 1.7883\n",
            "Epoch [20/100], Step [1700/1875], D Loss: 0.8203, G Loss: 2.0387\n",
            "Epoch [20/100], Step [1800/1875], D Loss: 1.0934, G Loss: 2.3555\n",
            "Epoch [21/100], Step [100/1875], D Loss: 0.9266, G Loss: 1.4620\n",
            "Epoch [21/100], Step [200/1875], D Loss: 0.5790, G Loss: 2.7339\n",
            "Epoch [21/100], Step [300/1875], D Loss: 0.4540, G Loss: 2.2869\n",
            "Epoch [21/100], Step [400/1875], D Loss: 0.6335, G Loss: 1.5920\n",
            "Epoch [21/100], Step [500/1875], D Loss: 0.6801, G Loss: 2.7184\n",
            "Epoch [21/100], Step [600/1875], D Loss: 0.6039, G Loss: 2.8388\n",
            "Epoch [21/100], Step [700/1875], D Loss: 0.4514, G Loss: 2.3162\n",
            "Epoch [21/100], Step [800/1875], D Loss: 0.5754, G Loss: 2.3525\n",
            "Epoch [21/100], Step [900/1875], D Loss: 0.9879, G Loss: 2.1958\n",
            "Epoch [21/100], Step [1000/1875], D Loss: 0.5988, G Loss: 3.2048\n",
            "Epoch [21/100], Step [1100/1875], D Loss: 0.8251, G Loss: 3.0858\n",
            "Epoch [21/100], Step [1200/1875], D Loss: 0.6796, G Loss: 2.3870\n",
            "Epoch [21/100], Step [1300/1875], D Loss: 0.6425, G Loss: 2.7109\n",
            "Epoch [21/100], Step [1400/1875], D Loss: 0.3649, G Loss: 3.0040\n",
            "Epoch [21/100], Step [1500/1875], D Loss: 0.4444, G Loss: 2.9024\n",
            "Epoch [21/100], Step [1600/1875], D Loss: 0.5214, G Loss: 2.3325\n",
            "Epoch [21/100], Step [1700/1875], D Loss: 0.4107, G Loss: 2.8394\n",
            "Epoch [21/100], Step [1800/1875], D Loss: 0.3597, G Loss: 3.2470\n",
            "Epoch [22/100], Step [100/1875], D Loss: 0.8238, G Loss: 1.6657\n",
            "Epoch [22/100], Step [200/1875], D Loss: 1.1200, G Loss: 1.9284\n",
            "Epoch [22/100], Step [300/1875], D Loss: 0.4098, G Loss: 2.5399\n",
            "Epoch [22/100], Step [400/1875], D Loss: 0.8930, G Loss: 2.7074\n",
            "Epoch [22/100], Step [500/1875], D Loss: 0.9958, G Loss: 2.2900\n",
            "Epoch [22/100], Step [600/1875], D Loss: 1.0503, G Loss: 2.5018\n",
            "Epoch [22/100], Step [700/1875], D Loss: 0.7102, G Loss: 2.7285\n",
            "Epoch [22/100], Step [800/1875], D Loss: 0.6817, G Loss: 2.3301\n",
            "Epoch [22/100], Step [900/1875], D Loss: 0.9115, G Loss: 2.2569\n",
            "Epoch [22/100], Step [1000/1875], D Loss: 0.5623, G Loss: 2.4216\n",
            "Epoch [22/100], Step [1100/1875], D Loss: 0.4904, G Loss: 3.1710\n",
            "Epoch [22/100], Step [1200/1875], D Loss: 0.5657, G Loss: 2.6847\n",
            "Epoch [22/100], Step [1300/1875], D Loss: 0.7369, G Loss: 2.4468\n",
            "Epoch [22/100], Step [1400/1875], D Loss: 0.6618, G Loss: 2.5883\n",
            "Epoch [22/100], Step [1500/1875], D Loss: 0.8019, G Loss: 2.2036\n",
            "Epoch [22/100], Step [1600/1875], D Loss: 0.7439, G Loss: 2.4904\n",
            "Epoch [22/100], Step [1700/1875], D Loss: 0.8076, G Loss: 2.6184\n",
            "Epoch [22/100], Step [1800/1875], D Loss: 0.4988, G Loss: 1.8251\n",
            "Epoch [23/100], Step [100/1875], D Loss: 0.6167, G Loss: 2.7308\n",
            "Epoch [23/100], Step [200/1875], D Loss: 1.0988, G Loss: 1.2567\n",
            "Epoch [23/100], Step [300/1875], D Loss: 0.7471, G Loss: 2.2745\n",
            "Epoch [23/100], Step [400/1875], D Loss: 0.6592, G Loss: 1.8718\n",
            "Epoch [23/100], Step [500/1875], D Loss: 0.8882, G Loss: 2.0342\n",
            "Epoch [23/100], Step [600/1875], D Loss: 0.8024, G Loss: 2.6502\n",
            "Epoch [23/100], Step [700/1875], D Loss: 0.9117, G Loss: 2.0673\n",
            "Epoch [23/100], Step [800/1875], D Loss: 0.8918, G Loss: 2.0665\n",
            "Epoch [23/100], Step [900/1875], D Loss: 0.5328, G Loss: 2.3624\n",
            "Epoch [23/100], Step [1000/1875], D Loss: 0.7995, G Loss: 1.8554\n",
            "Epoch [23/100], Step [1100/1875], D Loss: 0.7501, G Loss: 2.3096\n",
            "Epoch [23/100], Step [1200/1875], D Loss: 0.5313, G Loss: 2.2388\n",
            "Epoch [23/100], Step [1300/1875], D Loss: 0.5587, G Loss: 2.0324\n",
            "Epoch [23/100], Step [1400/1875], D Loss: 0.7685, G Loss: 1.5792\n",
            "Epoch [23/100], Step [1500/1875], D Loss: 0.6078, G Loss: 1.7832\n",
            "Epoch [23/100], Step [1600/1875], D Loss: 0.6802, G Loss: 2.5539\n",
            "Epoch [23/100], Step [1700/1875], D Loss: 1.1358, G Loss: 1.6352\n",
            "Epoch [23/100], Step [1800/1875], D Loss: 0.7476, G Loss: 2.4966\n",
            "Epoch [24/100], Step [100/1875], D Loss: 0.7208, G Loss: 2.0136\n",
            "Epoch [24/100], Step [200/1875], D Loss: 0.8463, G Loss: 2.5436\n",
            "Epoch [24/100], Step [300/1875], D Loss: 0.7824, G Loss: 2.1785\n",
            "Epoch [24/100], Step [400/1875], D Loss: 0.7914, G Loss: 1.5944\n",
            "Epoch [24/100], Step [500/1875], D Loss: 0.6159, G Loss: 2.4574\n",
            "Epoch [24/100], Step [600/1875], D Loss: 0.7453, G Loss: 1.9283\n",
            "Epoch [24/100], Step [700/1875], D Loss: 0.5045, G Loss: 2.4565\n",
            "Epoch [24/100], Step [800/1875], D Loss: 0.9344, G Loss: 1.6889\n",
            "Epoch [24/100], Step [900/1875], D Loss: 0.5501, G Loss: 1.9683\n",
            "Epoch [24/100], Step [1000/1875], D Loss: 0.4565, G Loss: 2.5592\n",
            "Epoch [24/100], Step [1100/1875], D Loss: 0.7888, G Loss: 1.9755\n",
            "Epoch [24/100], Step [1200/1875], D Loss: 1.0399, G Loss: 2.5854\n",
            "Epoch [24/100], Step [1300/1875], D Loss: 0.6750, G Loss: 1.6837\n",
            "Epoch [24/100], Step [1400/1875], D Loss: 0.6476, G Loss: 2.4234\n",
            "Epoch [24/100], Step [1500/1875], D Loss: 0.8260, G Loss: 1.6196\n",
            "Epoch [24/100], Step [1600/1875], D Loss: 0.5968, G Loss: 2.4042\n",
            "Epoch [24/100], Step [1700/1875], D Loss: 1.2692, G Loss: 2.2957\n",
            "Epoch [24/100], Step [1800/1875], D Loss: 0.7044, G Loss: 2.0187\n",
            "Epoch [25/100], Step [100/1875], D Loss: 0.5157, G Loss: 2.4179\n",
            "Epoch [25/100], Step [200/1875], D Loss: 0.8977, G Loss: 2.0957\n",
            "Epoch [25/100], Step [300/1875], D Loss: 0.9542, G Loss: 2.3766\n",
            "Epoch [25/100], Step [400/1875], D Loss: 0.7584, G Loss: 2.2449\n",
            "Epoch [25/100], Step [500/1875], D Loss: 0.9621, G Loss: 1.9316\n",
            "Epoch [25/100], Step [600/1875], D Loss: 1.0327, G Loss: 1.6829\n",
            "Epoch [25/100], Step [700/1875], D Loss: 0.8680, G Loss: 1.7581\n",
            "Epoch [25/100], Step [800/1875], D Loss: 0.4276, G Loss: 2.2039\n",
            "Epoch [25/100], Step [900/1875], D Loss: 1.1223, G Loss: 1.6731\n",
            "Epoch [25/100], Step [1000/1875], D Loss: 0.7869, G Loss: 2.1345\n",
            "Epoch [25/100], Step [1100/1875], D Loss: 0.6373, G Loss: 2.6586\n",
            "Epoch [25/100], Step [1200/1875], D Loss: 0.8147, G Loss: 2.3848\n",
            "Epoch [25/100], Step [1300/1875], D Loss: 0.8460, G Loss: 1.6220\n",
            "Epoch [25/100], Step [1400/1875], D Loss: 0.5590, G Loss: 2.1284\n",
            "Epoch [25/100], Step [1500/1875], D Loss: 1.1137, G Loss: 1.7378\n",
            "Epoch [25/100], Step [1600/1875], D Loss: 0.7098, G Loss: 2.6156\n",
            "Epoch [25/100], Step [1700/1875], D Loss: 1.0147, G Loss: 1.2793\n",
            "Epoch [25/100], Step [1800/1875], D Loss: 0.6554, G Loss: 1.7731\n",
            "Epoch [26/100], Step [100/1875], D Loss: 0.8826, G Loss: 2.0570\n",
            "Epoch [26/100], Step [200/1875], D Loss: 0.7410, G Loss: 2.5954\n",
            "Epoch [26/100], Step [300/1875], D Loss: 0.8716, G Loss: 2.0080\n",
            "Epoch [26/100], Step [400/1875], D Loss: 0.8136, G Loss: 1.8005\n",
            "Epoch [26/100], Step [500/1875], D Loss: 0.6932, G Loss: 2.1010\n",
            "Epoch [26/100], Step [600/1875], D Loss: 0.8683, G Loss: 1.5557\n",
            "Epoch [26/100], Step [700/1875], D Loss: 0.9270, G Loss: 2.0808\n",
            "Epoch [26/100], Step [800/1875], D Loss: 0.9312, G Loss: 1.6074\n",
            "Epoch [26/100], Step [900/1875], D Loss: 0.7935, G Loss: 2.2305\n",
            "Epoch [26/100], Step [1000/1875], D Loss: 0.8850, G Loss: 1.7704\n",
            "Epoch [26/100], Step [1100/1875], D Loss: 0.7663, G Loss: 1.8006\n",
            "Epoch [26/100], Step [1200/1875], D Loss: 0.7123, G Loss: 2.6505\n",
            "Epoch [26/100], Step [1300/1875], D Loss: 0.9747, G Loss: 2.2250\n",
            "Epoch [26/100], Step [1400/1875], D Loss: 0.8589, G Loss: 1.3202\n",
            "Epoch [26/100], Step [1500/1875], D Loss: 0.8198, G Loss: 2.1175\n",
            "Epoch [26/100], Step [1600/1875], D Loss: 1.1621, G Loss: 2.2236\n",
            "Epoch [26/100], Step [1700/1875], D Loss: 0.7027, G Loss: 1.5019\n",
            "Epoch [26/100], Step [1800/1875], D Loss: 0.8184, G Loss: 1.5852\n",
            "Epoch [27/100], Step [100/1875], D Loss: 1.0220, G Loss: 2.2526\n",
            "Epoch [27/100], Step [200/1875], D Loss: 0.6538, G Loss: 3.1125\n",
            "Epoch [27/100], Step [300/1875], D Loss: 0.9621, G Loss: 1.3660\n",
            "Epoch [27/100], Step [400/1875], D Loss: 0.9700, G Loss: 1.5569\n",
            "Epoch [27/100], Step [500/1875], D Loss: 0.7372, G Loss: 1.9169\n",
            "Epoch [27/100], Step [600/1875], D Loss: 0.3781, G Loss: 2.2758\n",
            "Epoch [27/100], Step [700/1875], D Loss: 0.7122, G Loss: 1.3358\n",
            "Epoch [27/100], Step [800/1875], D Loss: 0.8551, G Loss: 2.1400\n",
            "Epoch [27/100], Step [900/1875], D Loss: 1.0181, G Loss: 1.2291\n",
            "Epoch [27/100], Step [1000/1875], D Loss: 1.1701, G Loss: 1.9741\n",
            "Epoch [27/100], Step [1100/1875], D Loss: 0.6626, G Loss: 2.5425\n",
            "Epoch [27/100], Step [1200/1875], D Loss: 0.8480, G Loss: 1.8374\n",
            "Epoch [27/100], Step [1300/1875], D Loss: 0.8243, G Loss: 2.1163\n",
            "Epoch [27/100], Step [1400/1875], D Loss: 1.0237, G Loss: 1.9519\n",
            "Epoch [27/100], Step [1500/1875], D Loss: 1.1332, G Loss: 1.7003\n",
            "Epoch [27/100], Step [1600/1875], D Loss: 0.5864, G Loss: 1.7367\n",
            "Epoch [27/100], Step [1700/1875], D Loss: 0.6865, G Loss: 1.6205\n",
            "Epoch [27/100], Step [1800/1875], D Loss: 0.7823, G Loss: 1.5271\n",
            "Epoch [28/100], Step [100/1875], D Loss: 0.6686, G Loss: 1.4101\n",
            "Epoch [28/100], Step [200/1875], D Loss: 0.9740, G Loss: 1.9553\n",
            "Epoch [28/100], Step [300/1875], D Loss: 0.7338, G Loss: 1.9241\n",
            "Epoch [28/100], Step [400/1875], D Loss: 0.8498, G Loss: 1.5485\n",
            "Epoch [28/100], Step [500/1875], D Loss: 0.6257, G Loss: 2.1515\n",
            "Epoch [28/100], Step [600/1875], D Loss: 0.8056, G Loss: 2.6755\n",
            "Epoch [28/100], Step [700/1875], D Loss: 0.8096, G Loss: 2.1550\n",
            "Epoch [28/100], Step [800/1875], D Loss: 1.3557, G Loss: 1.4657\n",
            "Epoch [28/100], Step [900/1875], D Loss: 1.1798, G Loss: 1.0817\n",
            "Epoch [28/100], Step [1000/1875], D Loss: 0.8054, G Loss: 1.9409\n",
            "Epoch [28/100], Step [1100/1875], D Loss: 1.2064, G Loss: 1.7475\n",
            "Epoch [28/100], Step [1200/1875], D Loss: 0.9369, G Loss: 2.2646\n",
            "Epoch [28/100], Step [1300/1875], D Loss: 1.1090, G Loss: 1.9305\n",
            "Epoch [28/100], Step [1400/1875], D Loss: 0.8657, G Loss: 2.9073\n",
            "Epoch [28/100], Step [1500/1875], D Loss: 0.8412, G Loss: 1.6300\n",
            "Epoch [28/100], Step [1600/1875], D Loss: 0.8543, G Loss: 1.9512\n",
            "Epoch [28/100], Step [1700/1875], D Loss: 0.7863, G Loss: 2.3992\n",
            "Epoch [28/100], Step [1800/1875], D Loss: 0.8779, G Loss: 2.1464\n",
            "Epoch [29/100], Step [100/1875], D Loss: 0.5840, G Loss: 1.8175\n",
            "Epoch [29/100], Step [200/1875], D Loss: 0.8172, G Loss: 1.7006\n",
            "Epoch [29/100], Step [300/1875], D Loss: 0.9486, G Loss: 1.1983\n",
            "Epoch [29/100], Step [400/1875], D Loss: 0.9104, G Loss: 1.3813\n",
            "Epoch [29/100], Step [500/1875], D Loss: 0.7848, G Loss: 1.9361\n",
            "Epoch [29/100], Step [600/1875], D Loss: 0.7845, G Loss: 1.7694\n",
            "Epoch [29/100], Step [700/1875], D Loss: 0.7005, G Loss: 1.8195\n",
            "Epoch [29/100], Step [800/1875], D Loss: 0.8835, G Loss: 1.5612\n",
            "Epoch [29/100], Step [900/1875], D Loss: 0.8674, G Loss: 1.7646\n",
            "Epoch [29/100], Step [1000/1875], D Loss: 0.8472, G Loss: 1.8370\n",
            "Epoch [29/100], Step [1100/1875], D Loss: 0.6748, G Loss: 1.9250\n",
            "Epoch [29/100], Step [1200/1875], D Loss: 0.9435, G Loss: 1.3290\n",
            "Epoch [29/100], Step [1300/1875], D Loss: 0.7390, G Loss: 2.0307\n",
            "Epoch [29/100], Step [1400/1875], D Loss: 0.9723, G Loss: 1.5920\n",
            "Epoch [29/100], Step [1500/1875], D Loss: 0.8097, G Loss: 1.8304\n",
            "Epoch [29/100], Step [1600/1875], D Loss: 0.7903, G Loss: 1.6565\n",
            "Epoch [29/100], Step [1700/1875], D Loss: 0.8293, G Loss: 2.4831\n",
            "Epoch [29/100], Step [1800/1875], D Loss: 0.8803, G Loss: 1.4720\n",
            "Epoch [30/100], Step [100/1875], D Loss: 0.5294, G Loss: 1.7741\n",
            "Epoch [30/100], Step [200/1875], D Loss: 0.8554, G Loss: 2.0200\n",
            "Epoch [30/100], Step [300/1875], D Loss: 1.0702, G Loss: 1.4810\n",
            "Epoch [30/100], Step [400/1875], D Loss: 0.8748, G Loss: 1.4175\n",
            "Epoch [30/100], Step [500/1875], D Loss: 0.6914, G Loss: 2.0420\n",
            "Epoch [30/100], Step [600/1875], D Loss: 0.8332, G Loss: 1.4072\n",
            "Epoch [30/100], Step [700/1875], D Loss: 1.1761, G Loss: 1.4768\n",
            "Epoch [30/100], Step [800/1875], D Loss: 0.8261, G Loss: 2.0718\n",
            "Epoch [30/100], Step [900/1875], D Loss: 0.7243, G Loss: 1.8112\n",
            "Epoch [30/100], Step [1000/1875], D Loss: 0.9269, G Loss: 1.8947\n",
            "Epoch [30/100], Step [1100/1875], D Loss: 0.7332, G Loss: 1.7513\n",
            "Epoch [30/100], Step [1200/1875], D Loss: 1.1443, G Loss: 1.9521\n",
            "Epoch [30/100], Step [1300/1875], D Loss: 0.7925, G Loss: 1.8269\n",
            "Epoch [30/100], Step [1400/1875], D Loss: 0.5886, G Loss: 2.0579\n",
            "Epoch [30/100], Step [1500/1875], D Loss: 0.8902, G Loss: 2.0989\n",
            "Epoch [30/100], Step [1600/1875], D Loss: 0.8369, G Loss: 1.9623\n",
            "Epoch [30/100], Step [1700/1875], D Loss: 0.6985, G Loss: 1.7975\n",
            "Epoch [30/100], Step [1800/1875], D Loss: 0.7279, G Loss: 2.1039\n",
            "Epoch [31/100], Step [100/1875], D Loss: 1.1278, G Loss: 1.9377\n",
            "Epoch [31/100], Step [200/1875], D Loss: 0.7902, G Loss: 1.3477\n",
            "Epoch [31/100], Step [300/1875], D Loss: 0.7521, G Loss: 1.9730\n",
            "Epoch [31/100], Step [400/1875], D Loss: 0.5844, G Loss: 1.7536\n",
            "Epoch [31/100], Step [500/1875], D Loss: 0.8448, G Loss: 1.8064\n",
            "Epoch [31/100], Step [600/1875], D Loss: 0.9140, G Loss: 1.5116\n",
            "Epoch [31/100], Step [700/1875], D Loss: 0.7851, G Loss: 1.8519\n",
            "Epoch [31/100], Step [800/1875], D Loss: 0.9218, G Loss: 1.7228\n",
            "Epoch [31/100], Step [900/1875], D Loss: 0.6975, G Loss: 2.1895\n",
            "Epoch [31/100], Step [1000/1875], D Loss: 0.7183, G Loss: 1.6862\n",
            "Epoch [31/100], Step [1100/1875], D Loss: 0.6684, G Loss: 1.9633\n",
            "Epoch [31/100], Step [1200/1875], D Loss: 0.9332, G Loss: 1.6607\n",
            "Epoch [31/100], Step [1300/1875], D Loss: 1.0390, G Loss: 1.5059\n",
            "Epoch [31/100], Step [1400/1875], D Loss: 0.9310, G Loss: 2.1029\n",
            "Epoch [31/100], Step [1500/1875], D Loss: 1.0621, G Loss: 1.2962\n",
            "Epoch [31/100], Step [1600/1875], D Loss: 0.7195, G Loss: 1.9150\n",
            "Epoch [31/100], Step [1700/1875], D Loss: 1.0871, G Loss: 1.8998\n",
            "Epoch [31/100], Step [1800/1875], D Loss: 0.8465, G Loss: 1.6899\n",
            "Epoch [32/100], Step [100/1875], D Loss: 0.9923, G Loss: 2.1021\n",
            "Epoch [32/100], Step [200/1875], D Loss: 0.7066, G Loss: 1.5943\n",
            "Epoch [32/100], Step [300/1875], D Loss: 0.9746, G Loss: 1.6259\n",
            "Epoch [32/100], Step [400/1875], D Loss: 0.6452, G Loss: 1.7883\n",
            "Epoch [32/100], Step [500/1875], D Loss: 0.9350, G Loss: 1.7436\n",
            "Epoch [32/100], Step [600/1875], D Loss: 0.7513, G Loss: 1.6962\n",
            "Epoch [32/100], Step [700/1875], D Loss: 0.9396, G Loss: 1.4769\n",
            "Epoch [32/100], Step [800/1875], D Loss: 0.8145, G Loss: 1.8453\n",
            "Epoch [32/100], Step [900/1875], D Loss: 0.8670, G Loss: 2.0195\n",
            "Epoch [32/100], Step [1000/1875], D Loss: 1.0140, G Loss: 1.5896\n",
            "Epoch [32/100], Step [1100/1875], D Loss: 0.7250, G Loss: 1.5799\n",
            "Epoch [32/100], Step [1200/1875], D Loss: 1.0844, G Loss: 1.6773\n",
            "Epoch [32/100], Step [1300/1875], D Loss: 0.9607, G Loss: 1.9512\n",
            "Epoch [32/100], Step [1400/1875], D Loss: 0.8089, G Loss: 1.3285\n",
            "Epoch [32/100], Step [1500/1875], D Loss: 1.0151, G Loss: 1.2028\n",
            "Epoch [32/100], Step [1600/1875], D Loss: 1.1286, G Loss: 1.6895\n",
            "Epoch [32/100], Step [1700/1875], D Loss: 0.8892, G Loss: 1.5463\n",
            "Epoch [32/100], Step [1800/1875], D Loss: 0.9337, G Loss: 1.3591\n",
            "Epoch [33/100], Step [100/1875], D Loss: 1.1044, G Loss: 1.4780\n",
            "Epoch [33/100], Step [200/1875], D Loss: 0.4905, G Loss: 2.5740\n",
            "Epoch [33/100], Step [300/1875], D Loss: 0.7775, G Loss: 1.7059\n",
            "Epoch [33/100], Step [400/1875], D Loss: 1.1936, G Loss: 1.8282\n",
            "Epoch [33/100], Step [500/1875], D Loss: 1.0967, G Loss: 1.3145\n",
            "Epoch [33/100], Step [600/1875], D Loss: 0.8530, G Loss: 1.9591\n",
            "Epoch [33/100], Step [700/1875], D Loss: 0.9461, G Loss: 1.1455\n",
            "Epoch [33/100], Step [800/1875], D Loss: 0.7516, G Loss: 1.5413\n",
            "Epoch [33/100], Step [900/1875], D Loss: 0.8882, G Loss: 1.2847\n",
            "Epoch [33/100], Step [1000/1875], D Loss: 1.1812, G Loss: 0.7180\n",
            "Epoch [33/100], Step [1100/1875], D Loss: 1.1502, G Loss: 1.1920\n",
            "Epoch [33/100], Step [1200/1875], D Loss: 0.8894, G Loss: 1.9033\n",
            "Epoch [33/100], Step [1300/1875], D Loss: 1.1471, G Loss: 2.1690\n",
            "Epoch [33/100], Step [1400/1875], D Loss: 0.9988, G Loss: 1.5511\n",
            "Epoch [33/100], Step [1500/1875], D Loss: 1.0688, G Loss: 1.5246\n",
            "Epoch [33/100], Step [1600/1875], D Loss: 1.1964, G Loss: 2.0268\n",
            "Epoch [33/100], Step [1700/1875], D Loss: 0.6814, G Loss: 2.5489\n",
            "Epoch [33/100], Step [1800/1875], D Loss: 1.0418, G Loss: 1.4938\n",
            "Epoch [34/100], Step [100/1875], D Loss: 0.9321, G Loss: 1.6119\n",
            "Epoch [34/100], Step [200/1875], D Loss: 0.9057, G Loss: 1.2760\n",
            "Epoch [34/100], Step [300/1875], D Loss: 0.8187, G Loss: 1.8234\n",
            "Epoch [34/100], Step [400/1875], D Loss: 0.9104, G Loss: 1.5227\n",
            "Epoch [34/100], Step [500/1875], D Loss: 0.7623, G Loss: 1.3527\n",
            "Epoch [34/100], Step [600/1875], D Loss: 1.0610, G Loss: 1.1721\n",
            "Epoch [34/100], Step [700/1875], D Loss: 0.9019, G Loss: 1.3010\n",
            "Epoch [34/100], Step [800/1875], D Loss: 1.1606, G Loss: 1.3032\n",
            "Epoch [34/100], Step [900/1875], D Loss: 1.3726, G Loss: 0.8041\n",
            "Epoch [34/100], Step [1000/1875], D Loss: 1.4423, G Loss: 1.0456\n",
            "Epoch [34/100], Step [1100/1875], D Loss: 1.0819, G Loss: 1.4204\n",
            "Epoch [34/100], Step [1200/1875], D Loss: 0.9482, G Loss: 1.2589\n",
            "Epoch [34/100], Step [1300/1875], D Loss: 1.2655, G Loss: 1.2299\n",
            "Epoch [34/100], Step [1400/1875], D Loss: 1.0346, G Loss: 1.4552\n",
            "Epoch [34/100], Step [1500/1875], D Loss: 1.0264, G Loss: 1.2547\n",
            "Epoch [34/100], Step [1600/1875], D Loss: 0.8589, G Loss: 1.7322\n",
            "Epoch [34/100], Step [1700/1875], D Loss: 0.8173, G Loss: 1.8788\n",
            "Epoch [34/100], Step [1800/1875], D Loss: 1.3535, G Loss: 0.9598\n",
            "Epoch [35/100], Step [100/1875], D Loss: 0.9460, G Loss: 1.3045\n",
            "Epoch [35/100], Step [200/1875], D Loss: 0.7052, G Loss: 1.8669\n",
            "Epoch [35/100], Step [300/1875], D Loss: 0.8751, G Loss: 1.5282\n",
            "Epoch [35/100], Step [400/1875], D Loss: 0.9576, G Loss: 1.5983\n",
            "Epoch [35/100], Step [500/1875], D Loss: 0.8438, G Loss: 1.4071\n",
            "Epoch [35/100], Step [600/1875], D Loss: 1.0729, G Loss: 1.6912\n",
            "Epoch [35/100], Step [700/1875], D Loss: 0.9322, G Loss: 1.4319\n",
            "Epoch [35/100], Step [800/1875], D Loss: 1.3226, G Loss: 0.9177\n",
            "Epoch [35/100], Step [900/1875], D Loss: 0.9233, G Loss: 1.6856\n",
            "Epoch [35/100], Step [1000/1875], D Loss: 1.0884, G Loss: 1.5453\n",
            "Epoch [35/100], Step [1100/1875], D Loss: 0.9209, G Loss: 1.3947\n",
            "Epoch [35/100], Step [1200/1875], D Loss: 1.0060, G Loss: 1.2797\n",
            "Epoch [35/100], Step [1300/1875], D Loss: 1.1855, G Loss: 1.1374\n",
            "Epoch [35/100], Step [1400/1875], D Loss: 1.0663, G Loss: 1.3244\n",
            "Epoch [35/100], Step [1500/1875], D Loss: 0.9522, G Loss: 1.6146\n",
            "Epoch [35/100], Step [1600/1875], D Loss: 0.8003, G Loss: 1.9507\n",
            "Epoch [35/100], Step [1700/1875], D Loss: 1.0512, G Loss: 1.4250\n",
            "Epoch [35/100], Step [1800/1875], D Loss: 1.2525, G Loss: 2.1058\n",
            "Epoch [36/100], Step [100/1875], D Loss: 1.0149, G Loss: 1.2757\n",
            "Epoch [36/100], Step [200/1875], D Loss: 0.9185, G Loss: 1.4597\n",
            "Epoch [36/100], Step [300/1875], D Loss: 0.7384, G Loss: 1.8391\n",
            "Epoch [36/100], Step [400/1875], D Loss: 1.1007, G Loss: 1.4148\n",
            "Epoch [36/100], Step [500/1875], D Loss: 1.0125, G Loss: 1.6260\n",
            "Epoch [36/100], Step [600/1875], D Loss: 0.9651, G Loss: 1.5362\n",
            "Epoch [36/100], Step [700/1875], D Loss: 1.0385, G Loss: 1.4247\n",
            "Epoch [36/100], Step [800/1875], D Loss: 1.1709, G Loss: 1.5062\n",
            "Epoch [36/100], Step [900/1875], D Loss: 1.0783, G Loss: 1.3176\n",
            "Epoch [36/100], Step [1000/1875], D Loss: 1.1790, G Loss: 1.1524\n",
            "Epoch [36/100], Step [1100/1875], D Loss: 0.9030, G Loss: 1.6472\n",
            "Epoch [36/100], Step [1200/1875], D Loss: 1.0157, G Loss: 1.2432\n",
            "Epoch [36/100], Step [1300/1875], D Loss: 0.9767, G Loss: 1.4354\n",
            "Epoch [36/100], Step [1400/1875], D Loss: 1.1362, G Loss: 1.3250\n",
            "Epoch [36/100], Step [1500/1875], D Loss: 1.1307, G Loss: 1.5703\n",
            "Epoch [36/100], Step [1600/1875], D Loss: 1.1272, G Loss: 1.4554\n",
            "Epoch [36/100], Step [1700/1875], D Loss: 1.0518, G Loss: 1.5452\n",
            "Epoch [36/100], Step [1800/1875], D Loss: 1.0015, G Loss: 1.4728\n",
            "Epoch [37/100], Step [100/1875], D Loss: 0.9328, G Loss: 1.4825\n",
            "Epoch [37/100], Step [200/1875], D Loss: 0.9429, G Loss: 1.3775\n",
            "Epoch [37/100], Step [300/1875], D Loss: 0.8749, G Loss: 1.7494\n",
            "Epoch [37/100], Step [400/1875], D Loss: 1.0787, G Loss: 1.3153\n",
            "Epoch [37/100], Step [500/1875], D Loss: 1.0750, G Loss: 1.2850\n",
            "Epoch [37/100], Step [600/1875], D Loss: 0.9147, G Loss: 1.3783\n",
            "Epoch [37/100], Step [700/1875], D Loss: 1.0698, G Loss: 1.2513\n",
            "Epoch [37/100], Step [800/1875], D Loss: 0.8995, G Loss: 1.6078\n",
            "Epoch [37/100], Step [900/1875], D Loss: 0.9934, G Loss: 1.6282\n",
            "Epoch [37/100], Step [1000/1875], D Loss: 1.0273, G Loss: 1.1767\n",
            "Epoch [37/100], Step [1100/1875], D Loss: 0.9075, G Loss: 1.5603\n",
            "Epoch [37/100], Step [1200/1875], D Loss: 1.0459, G Loss: 1.0850\n",
            "Epoch [37/100], Step [1300/1875], D Loss: 1.0633, G Loss: 1.5581\n",
            "Epoch [37/100], Step [1400/1875], D Loss: 1.0636, G Loss: 1.5060\n",
            "Epoch [37/100], Step [1500/1875], D Loss: 1.1045, G Loss: 1.4687\n",
            "Epoch [37/100], Step [1600/1875], D Loss: 1.0865, G Loss: 1.5266\n",
            "Epoch [37/100], Step [1700/1875], D Loss: 0.9909, G Loss: 1.2512\n",
            "Epoch [37/100], Step [1800/1875], D Loss: 0.9102, G Loss: 1.5052\n",
            "Epoch [38/100], Step [100/1875], D Loss: 0.8921, G Loss: 1.2897\n",
            "Epoch [38/100], Step [200/1875], D Loss: 0.8972, G Loss: 1.2436\n",
            "Epoch [38/100], Step [300/1875], D Loss: 1.2911, G Loss: 1.7358\n",
            "Epoch [38/100], Step [400/1875], D Loss: 1.1543, G Loss: 1.5101\n",
            "Epoch [38/100], Step [500/1875], D Loss: 1.0913, G Loss: 1.4748\n",
            "Epoch [38/100], Step [600/1875], D Loss: 0.9559, G Loss: 1.5118\n",
            "Epoch [38/100], Step [700/1875], D Loss: 0.9613, G Loss: 1.1429\n",
            "Epoch [38/100], Step [800/1875], D Loss: 1.1720, G Loss: 1.1832\n",
            "Epoch [38/100], Step [900/1875], D Loss: 0.8951, G Loss: 1.8340\n",
            "Epoch [38/100], Step [1000/1875], D Loss: 0.9823, G Loss: 1.2289\n",
            "Epoch [38/100], Step [1100/1875], D Loss: 0.8426, G Loss: 1.5887\n",
            "Epoch [38/100], Step [1200/1875], D Loss: 1.0136, G Loss: 1.6475\n",
            "Epoch [38/100], Step [1300/1875], D Loss: 1.1310, G Loss: 1.4797\n",
            "Epoch [38/100], Step [1400/1875], D Loss: 1.2023, G Loss: 1.0242\n",
            "Epoch [38/100], Step [1500/1875], D Loss: 0.9969, G Loss: 1.5872\n",
            "Epoch [38/100], Step [1600/1875], D Loss: 1.2715, G Loss: 1.5715\n",
            "Epoch [38/100], Step [1700/1875], D Loss: 1.0520, G Loss: 1.5714\n",
            "Epoch [38/100], Step [1800/1875], D Loss: 1.0684, G Loss: 1.2835\n",
            "Epoch [39/100], Step [100/1875], D Loss: 0.9824, G Loss: 1.3117\n",
            "Epoch [39/100], Step [200/1875], D Loss: 0.9068, G Loss: 1.4675\n",
            "Epoch [39/100], Step [300/1875], D Loss: 0.9617, G Loss: 1.6177\n",
            "Epoch [39/100], Step [400/1875], D Loss: 0.8623, G Loss: 1.5790\n",
            "Epoch [39/100], Step [500/1875], D Loss: 0.9856, G Loss: 1.2501\n",
            "Epoch [39/100], Step [600/1875], D Loss: 1.1150, G Loss: 1.4224\n",
            "Epoch [39/100], Step [700/1875], D Loss: 0.8913, G Loss: 1.1024\n",
            "Epoch [39/100], Step [800/1875], D Loss: 1.0049, G Loss: 1.0565\n",
            "Epoch [39/100], Step [900/1875], D Loss: 1.0006, G Loss: 1.0454\n",
            "Epoch [39/100], Step [1000/1875], D Loss: 1.0240, G Loss: 1.6484\n",
            "Epoch [39/100], Step [1100/1875], D Loss: 0.7954, G Loss: 1.6141\n",
            "Epoch [39/100], Step [1200/1875], D Loss: 1.1614, G Loss: 1.0259\n",
            "Epoch [39/100], Step [1300/1875], D Loss: 0.9087, G Loss: 1.3097\n",
            "Epoch [39/100], Step [1400/1875], D Loss: 1.1342, G Loss: 1.1629\n",
            "Epoch [39/100], Step [1500/1875], D Loss: 1.1215, G Loss: 1.3827\n",
            "Epoch [39/100], Step [1600/1875], D Loss: 0.9581, G Loss: 1.4292\n",
            "Epoch [39/100], Step [1700/1875], D Loss: 1.0545, G Loss: 1.3183\n",
            "Epoch [39/100], Step [1800/1875], D Loss: 1.0560, G Loss: 1.4885\n",
            "Epoch [40/100], Step [100/1875], D Loss: 0.8857, G Loss: 1.0788\n",
            "Epoch [40/100], Step [200/1875], D Loss: 1.1456, G Loss: 1.5163\n",
            "Epoch [40/100], Step [300/1875], D Loss: 1.0286, G Loss: 1.5481\n",
            "Epoch [40/100], Step [400/1875], D Loss: 1.2828, G Loss: 1.3366\n",
            "Epoch [40/100], Step [500/1875], D Loss: 0.8870, G Loss: 1.7417\n",
            "Epoch [40/100], Step [600/1875], D Loss: 1.0510, G Loss: 1.2971\n",
            "Epoch [40/100], Step [700/1875], D Loss: 1.0841, G Loss: 1.2037\n",
            "Epoch [40/100], Step [800/1875], D Loss: 1.0555, G Loss: 1.4025\n",
            "Epoch [40/100], Step [900/1875], D Loss: 0.8331, G Loss: 1.7818\n",
            "Epoch [40/100], Step [1000/1875], D Loss: 0.9673, G Loss: 1.6818\n",
            "Epoch [40/100], Step [1100/1875], D Loss: 1.1314, G Loss: 1.4059\n",
            "Epoch [40/100], Step [1200/1875], D Loss: 1.1226, G Loss: 0.9722\n",
            "Epoch [40/100], Step [1300/1875], D Loss: 1.1029, G Loss: 1.5504\n",
            "Epoch [40/100], Step [1400/1875], D Loss: 1.2398, G Loss: 1.2025\n",
            "Epoch [40/100], Step [1500/1875], D Loss: 1.0775, G Loss: 1.0978\n",
            "Epoch [40/100], Step [1600/1875], D Loss: 1.1571, G Loss: 1.1572\n",
            "Epoch [40/100], Step [1700/1875], D Loss: 1.0020, G Loss: 1.2733\n",
            "Epoch [40/100], Step [1800/1875], D Loss: 1.0605, G Loss: 1.1128\n",
            "Epoch [41/100], Step [100/1875], D Loss: 1.1253, G Loss: 1.2693\n",
            "Epoch [41/100], Step [200/1875], D Loss: 1.1222, G Loss: 1.4501\n",
            "Epoch [41/100], Step [300/1875], D Loss: 1.0116, G Loss: 1.4808\n",
            "Epoch [41/100], Step [400/1875], D Loss: 1.0854, G Loss: 1.4522\n",
            "Epoch [41/100], Step [500/1875], D Loss: 0.9264, G Loss: 1.4463\n",
            "Epoch [41/100], Step [600/1875], D Loss: 0.9335, G Loss: 1.2170\n",
            "Epoch [41/100], Step [700/1875], D Loss: 1.1575, G Loss: 1.4062\n",
            "Epoch [41/100], Step [800/1875], D Loss: 0.9753, G Loss: 1.5926\n",
            "Epoch [41/100], Step [900/1875], D Loss: 0.9006, G Loss: 1.2601\n",
            "Epoch [41/100], Step [1000/1875], D Loss: 1.2939, G Loss: 1.4285\n",
            "Epoch [41/100], Step [1100/1875], D Loss: 1.0979, G Loss: 0.9996\n",
            "Epoch [41/100], Step [1200/1875], D Loss: 1.2017, G Loss: 0.9685\n",
            "Epoch [41/100], Step [1300/1875], D Loss: 1.1869, G Loss: 1.5375\n",
            "Epoch [41/100], Step [1400/1875], D Loss: 0.9170, G Loss: 1.3314\n",
            "Epoch [41/100], Step [1500/1875], D Loss: 0.9489, G Loss: 1.5442\n",
            "Epoch [41/100], Step [1600/1875], D Loss: 1.3862, G Loss: 1.0158\n",
            "Epoch [41/100], Step [1700/1875], D Loss: 1.0049, G Loss: 1.5292\n",
            "Epoch [41/100], Step [1800/1875], D Loss: 1.0254, G Loss: 1.6732\n",
            "Epoch [42/100], Step [100/1875], D Loss: 1.1732, G Loss: 1.1915\n",
            "Epoch [42/100], Step [200/1875], D Loss: 1.2170, G Loss: 1.1894\n",
            "Epoch [42/100], Step [300/1875], D Loss: 1.3602, G Loss: 1.0687\n",
            "Epoch [42/100], Step [400/1875], D Loss: 0.9142, G Loss: 1.3416\n",
            "Epoch [42/100], Step [500/1875], D Loss: 0.9887, G Loss: 1.4964\n",
            "Epoch [42/100], Step [600/1875], D Loss: 1.2682, G Loss: 0.9282\n",
            "Epoch [42/100], Step [700/1875], D Loss: 1.0495, G Loss: 1.2193\n",
            "Epoch [42/100], Step [800/1875], D Loss: 0.7080, G Loss: 1.7472\n",
            "Epoch [42/100], Step [900/1875], D Loss: 0.9721, G Loss: 1.3360\n",
            "Epoch [42/100], Step [1000/1875], D Loss: 0.9126, G Loss: 1.6154\n",
            "Epoch [42/100], Step [1100/1875], D Loss: 0.9908, G Loss: 1.3688\n",
            "Epoch [42/100], Step [1200/1875], D Loss: 0.9459, G Loss: 0.9608\n",
            "Epoch [42/100], Step [1300/1875], D Loss: 1.0999, G Loss: 1.4303\n",
            "Epoch [42/100], Step [1400/1875], D Loss: 1.1477, G Loss: 1.2486\n",
            "Epoch [42/100], Step [1500/1875], D Loss: 0.9335, G Loss: 1.6632\n",
            "Epoch [42/100], Step [1600/1875], D Loss: 1.0213, G Loss: 1.1901\n",
            "Epoch [42/100], Step [1700/1875], D Loss: 1.0584, G Loss: 1.1908\n",
            "Epoch [42/100], Step [1800/1875], D Loss: 1.0573, G Loss: 1.0648\n",
            "Epoch [43/100], Step [100/1875], D Loss: 1.0696, G Loss: 1.4244\n",
            "Epoch [43/100], Step [200/1875], D Loss: 1.2021, G Loss: 1.4377\n",
            "Epoch [43/100], Step [300/1875], D Loss: 1.1922, G Loss: 1.2121\n",
            "Epoch [43/100], Step [400/1875], D Loss: 1.1140, G Loss: 0.9719\n",
            "Epoch [43/100], Step [500/1875], D Loss: 1.0111, G Loss: 1.2250\n",
            "Epoch [43/100], Step [600/1875], D Loss: 0.9211, G Loss: 1.2683\n",
            "Epoch [43/100], Step [700/1875], D Loss: 1.0106, G Loss: 1.7741\n",
            "Epoch [43/100], Step [800/1875], D Loss: 1.0628, G Loss: 1.0726\n",
            "Epoch [43/100], Step [900/1875], D Loss: 0.9400, G Loss: 1.4022\n",
            "Epoch [43/100], Step [1000/1875], D Loss: 1.0103, G Loss: 1.1246\n",
            "Epoch [43/100], Step [1100/1875], D Loss: 1.1088, G Loss: 1.4995\n",
            "Epoch [43/100], Step [1200/1875], D Loss: 0.9531, G Loss: 1.2330\n",
            "Epoch [43/100], Step [1300/1875], D Loss: 0.9908, G Loss: 1.1295\n",
            "Epoch [43/100], Step [1400/1875], D Loss: 1.2063, G Loss: 1.2081\n",
            "Epoch [43/100], Step [1500/1875], D Loss: 1.2620, G Loss: 1.0568\n",
            "Epoch [43/100], Step [1600/1875], D Loss: 1.2444, G Loss: 1.2832\n",
            "Epoch [43/100], Step [1700/1875], D Loss: 1.0694, G Loss: 1.1939\n",
            "Epoch [43/100], Step [1800/1875], D Loss: 1.2271, G Loss: 1.5086\n",
            "Epoch [44/100], Step [100/1875], D Loss: 1.2824, G Loss: 1.1577\n",
            "Epoch [44/100], Step [200/1875], D Loss: 1.0714, G Loss: 1.3679\n",
            "Epoch [44/100], Step [300/1875], D Loss: 0.9934, G Loss: 1.4337\n",
            "Epoch [44/100], Step [400/1875], D Loss: 1.1696, G Loss: 1.1752\n",
            "Epoch [44/100], Step [500/1875], D Loss: 1.3464, G Loss: 1.0474\n",
            "Epoch [44/100], Step [600/1875], D Loss: 1.3796, G Loss: 1.2294\n",
            "Epoch [44/100], Step [700/1875], D Loss: 1.2530, G Loss: 1.2011\n",
            "Epoch [44/100], Step [800/1875], D Loss: 0.9646, G Loss: 1.1483\n",
            "Epoch [44/100], Step [900/1875], D Loss: 0.9267, G Loss: 1.3699\n",
            "Epoch [44/100], Step [1000/1875], D Loss: 1.0278, G Loss: 1.2214\n",
            "Epoch [44/100], Step [1100/1875], D Loss: 0.9799, G Loss: 1.6253\n",
            "Epoch [44/100], Step [1200/1875], D Loss: 1.1308, G Loss: 1.2071\n",
            "Epoch [44/100], Step [1300/1875], D Loss: 1.0116, G Loss: 1.2191\n",
            "Epoch [44/100], Step [1400/1875], D Loss: 1.1058, G Loss: 0.9051\n",
            "Epoch [44/100], Step [1500/1875], D Loss: 0.9929, G Loss: 1.2740\n",
            "Epoch [44/100], Step [1600/1875], D Loss: 1.0035, G Loss: 1.2949\n",
            "Epoch [44/100], Step [1700/1875], D Loss: 1.1796, G Loss: 1.4181\n",
            "Epoch [44/100], Step [1800/1875], D Loss: 1.2543, G Loss: 0.9479\n",
            "Epoch [45/100], Step [100/1875], D Loss: 1.2045, G Loss: 1.5131\n",
            "Epoch [45/100], Step [200/1875], D Loss: 1.4104, G Loss: 0.9584\n",
            "Epoch [45/100], Step [300/1875], D Loss: 1.2634, G Loss: 1.2528\n",
            "Epoch [45/100], Step [400/1875], D Loss: 1.1396, G Loss: 1.0310\n",
            "Epoch [45/100], Step [500/1875], D Loss: 1.2132, G Loss: 1.3446\n",
            "Epoch [45/100], Step [600/1875], D Loss: 1.0572, G Loss: 1.2501\n",
            "Epoch [45/100], Step [700/1875], D Loss: 1.1815, G Loss: 1.0782\n",
            "Epoch [45/100], Step [800/1875], D Loss: 1.1193, G Loss: 1.2097\n",
            "Epoch [45/100], Step [900/1875], D Loss: 1.0225, G Loss: 1.0147\n",
            "Epoch [45/100], Step [1000/1875], D Loss: 0.7850, G Loss: 1.6200\n",
            "Epoch [45/100], Step [1100/1875], D Loss: 1.1546, G Loss: 1.1944\n",
            "Epoch [45/100], Step [1200/1875], D Loss: 1.2405, G Loss: 1.0202\n",
            "Epoch [45/100], Step [1300/1875], D Loss: 1.2625, G Loss: 1.0544\n",
            "Epoch [45/100], Step [1400/1875], D Loss: 0.8485, G Loss: 1.4691\n",
            "Epoch [45/100], Step [1500/1875], D Loss: 1.0038, G Loss: 1.2857\n",
            "Epoch [45/100], Step [1600/1875], D Loss: 1.0692, G Loss: 1.1527\n",
            "Epoch [45/100], Step [1700/1875], D Loss: 1.1166, G Loss: 0.9781\n",
            "Epoch [45/100], Step [1800/1875], D Loss: 1.0983, G Loss: 1.2921\n",
            "Epoch [46/100], Step [100/1875], D Loss: 0.9052, G Loss: 1.2794\n",
            "Epoch [46/100], Step [200/1875], D Loss: 1.2413, G Loss: 1.0108\n",
            "Epoch [46/100], Step [300/1875], D Loss: 1.0077, G Loss: 1.1412\n",
            "Epoch [46/100], Step [400/1875], D Loss: 1.1052, G Loss: 1.1656\n",
            "Epoch [46/100], Step [500/1875], D Loss: 0.9835, G Loss: 1.1813\n",
            "Epoch [46/100], Step [600/1875], D Loss: 1.0460, G Loss: 1.4068\n",
            "Epoch [46/100], Step [700/1875], D Loss: 1.2109, G Loss: 1.0123\n",
            "Epoch [46/100], Step [800/1875], D Loss: 0.8578, G Loss: 1.2197\n",
            "Epoch [46/100], Step [900/1875], D Loss: 1.0833, G Loss: 1.1220\n",
            "Epoch [46/100], Step [1000/1875], D Loss: 1.1181, G Loss: 1.4075\n",
            "Epoch [46/100], Step [1100/1875], D Loss: 1.0494, G Loss: 1.1418\n",
            "Epoch [46/100], Step [1200/1875], D Loss: 0.9809, G Loss: 1.2955\n",
            "Epoch [46/100], Step [1300/1875], D Loss: 1.1371, G Loss: 1.1141\n",
            "Epoch [46/100], Step [1400/1875], D Loss: 0.9717, G Loss: 1.2933\n",
            "Epoch [46/100], Step [1500/1875], D Loss: 1.0471, G Loss: 1.1388\n",
            "Epoch [46/100], Step [1600/1875], D Loss: 1.0934, G Loss: 1.3374\n",
            "Epoch [46/100], Step [1700/1875], D Loss: 1.1148, G Loss: 1.4061\n",
            "Epoch [46/100], Step [1800/1875], D Loss: 0.9478, G Loss: 1.2554\n",
            "Epoch [47/100], Step [100/1875], D Loss: 1.4571, G Loss: 1.2877\n",
            "Epoch [47/100], Step [200/1875], D Loss: 1.1518, G Loss: 1.0428\n",
            "Epoch [47/100], Step [300/1875], D Loss: 1.2349, G Loss: 1.2923\n",
            "Epoch [47/100], Step [400/1875], D Loss: 1.0032, G Loss: 1.4247\n",
            "Epoch [47/100], Step [500/1875], D Loss: 1.1423, G Loss: 1.2091\n",
            "Epoch [47/100], Step [600/1875], D Loss: 1.0071, G Loss: 1.7004\n",
            "Epoch [47/100], Step [700/1875], D Loss: 1.0658, G Loss: 1.3442\n",
            "Epoch [47/100], Step [800/1875], D Loss: 1.3563, G Loss: 1.0597\n",
            "Epoch [47/100], Step [900/1875], D Loss: 1.0971, G Loss: 1.6698\n",
            "Epoch [47/100], Step [1000/1875], D Loss: 0.9462, G Loss: 1.4667\n",
            "Epoch [47/100], Step [1100/1875], D Loss: 1.3737, G Loss: 1.1918\n",
            "Epoch [47/100], Step [1200/1875], D Loss: 1.1333, G Loss: 1.4130\n",
            "Epoch [47/100], Step [1300/1875], D Loss: 0.9941, G Loss: 1.4334\n",
            "Epoch [47/100], Step [1400/1875], D Loss: 1.1894, G Loss: 1.7780\n",
            "Epoch [47/100], Step [1500/1875], D Loss: 1.0870, G Loss: 1.3657\n",
            "Epoch [47/100], Step [1600/1875], D Loss: 1.0919, G Loss: 1.3630\n",
            "Epoch [47/100], Step [1700/1875], D Loss: 0.8738, G Loss: 1.3100\n",
            "Epoch [47/100], Step [1800/1875], D Loss: 1.2654, G Loss: 1.1032\n",
            "Epoch [48/100], Step [100/1875], D Loss: 1.2568, G Loss: 1.1490\n",
            "Epoch [48/100], Step [200/1875], D Loss: 1.2271, G Loss: 1.4590\n",
            "Epoch [48/100], Step [300/1875], D Loss: 1.3706, G Loss: 0.9495\n",
            "Epoch [48/100], Step [400/1875], D Loss: 1.0338, G Loss: 1.1356\n",
            "Epoch [48/100], Step [500/1875], D Loss: 0.9846, G Loss: 1.3969\n",
            "Epoch [48/100], Step [600/1875], D Loss: 1.0963, G Loss: 0.9533\n",
            "Epoch [48/100], Step [700/1875], D Loss: 1.1540, G Loss: 1.3044\n",
            "Epoch [48/100], Step [800/1875], D Loss: 0.8861, G Loss: 1.2986\n",
            "Epoch [48/100], Step [900/1875], D Loss: 1.2861, G Loss: 0.8361\n",
            "Epoch [48/100], Step [1000/1875], D Loss: 0.9353, G Loss: 1.3665\n",
            "Epoch [48/100], Step [1100/1875], D Loss: 1.1263, G Loss: 1.7605\n",
            "Epoch [48/100], Step [1200/1875], D Loss: 0.9555, G Loss: 1.4622\n",
            "Epoch [48/100], Step [1300/1875], D Loss: 1.1043, G Loss: 1.4115\n",
            "Epoch [48/100], Step [1400/1875], D Loss: 1.2204, G Loss: 0.9098\n",
            "Epoch [48/100], Step [1500/1875], D Loss: 1.1188, G Loss: 1.1930\n",
            "Epoch [48/100], Step [1600/1875], D Loss: 0.9548, G Loss: 1.3912\n",
            "Epoch [48/100], Step [1700/1875], D Loss: 1.2834, G Loss: 1.0512\n",
            "Epoch [48/100], Step [1800/1875], D Loss: 1.2258, G Loss: 1.0218\n",
            "Epoch [49/100], Step [100/1875], D Loss: 0.7493, G Loss: 1.3213\n",
            "Epoch [49/100], Step [200/1875], D Loss: 1.2983, G Loss: 1.0336\n",
            "Epoch [49/100], Step [300/1875], D Loss: 1.1929, G Loss: 1.0466\n",
            "Epoch [49/100], Step [400/1875], D Loss: 1.0028, G Loss: 1.6482\n",
            "Epoch [49/100], Step [500/1875], D Loss: 1.0319, G Loss: 1.0449\n",
            "Epoch [49/100], Step [600/1875], D Loss: 1.0394, G Loss: 1.3235\n",
            "Epoch [49/100], Step [700/1875], D Loss: 0.9956, G Loss: 1.2184\n",
            "Epoch [49/100], Step [800/1875], D Loss: 0.9821, G Loss: 0.9788\n",
            "Epoch [49/100], Step [900/1875], D Loss: 0.9905, G Loss: 1.4393\n",
            "Epoch [49/100], Step [1000/1875], D Loss: 0.9608, G Loss: 1.1625\n",
            "Epoch [49/100], Step [1100/1875], D Loss: 0.9552, G Loss: 1.5900\n",
            "Epoch [49/100], Step [1200/1875], D Loss: 1.0722, G Loss: 1.0022\n",
            "Epoch [49/100], Step [1300/1875], D Loss: 1.2207, G Loss: 1.3233\n",
            "Epoch [49/100], Step [1400/1875], D Loss: 1.0789, G Loss: 1.2533\n",
            "Epoch [49/100], Step [1500/1875], D Loss: 1.1599, G Loss: 1.3359\n",
            "Epoch [49/100], Step [1600/1875], D Loss: 1.0512, G Loss: 1.2280\n",
            "Epoch [49/100], Step [1700/1875], D Loss: 1.1707, G Loss: 1.3448\n",
            "Epoch [49/100], Step [1800/1875], D Loss: 1.2942, G Loss: 0.9158\n",
            "Epoch [50/100], Step [100/1875], D Loss: 1.0633, G Loss: 1.3728\n",
            "Epoch [50/100], Step [200/1875], D Loss: 1.2291, G Loss: 1.3629\n",
            "Epoch [50/100], Step [300/1875], D Loss: 0.9790, G Loss: 1.1033\n",
            "Epoch [50/100], Step [400/1875], D Loss: 1.3095, G Loss: 0.9936\n",
            "Epoch [50/100], Step [500/1875], D Loss: 1.0662, G Loss: 1.4779\n",
            "Epoch [50/100], Step [600/1875], D Loss: 1.0094, G Loss: 1.3859\n",
            "Epoch [50/100], Step [700/1875], D Loss: 1.1893, G Loss: 0.8825\n",
            "Epoch [50/100], Step [800/1875], D Loss: 0.9004, G Loss: 1.0616\n",
            "Epoch [50/100], Step [900/1875], D Loss: 1.0210, G Loss: 1.4220\n",
            "Epoch [50/100], Step [1000/1875], D Loss: 1.1219, G Loss: 1.2038\n",
            "Epoch [50/100], Step [1100/1875], D Loss: 1.2305, G Loss: 1.4127\n",
            "Epoch [50/100], Step [1200/1875], D Loss: 1.0151, G Loss: 1.3016\n",
            "Epoch [50/100], Step [1300/1875], D Loss: 0.9731, G Loss: 1.5552\n",
            "Epoch [50/100], Step [1400/1875], D Loss: 1.0810, G Loss: 1.1943\n",
            "Epoch [50/100], Step [1500/1875], D Loss: 1.1095, G Loss: 1.1269\n",
            "Epoch [50/100], Step [1600/1875], D Loss: 1.0982, G Loss: 1.2766\n",
            "Epoch [50/100], Step [1700/1875], D Loss: 1.0754, G Loss: 0.9086\n",
            "Epoch [50/100], Step [1800/1875], D Loss: 1.1830, G Loss: 1.2314\n",
            "Epoch [51/100], Step [100/1875], D Loss: 1.0956, G Loss: 1.0107\n",
            "Epoch [51/100], Step [200/1875], D Loss: 1.2076, G Loss: 1.2043\n",
            "Epoch [51/100], Step [300/1875], D Loss: 1.0566, G Loss: 1.0976\n",
            "Epoch [51/100], Step [400/1875], D Loss: 1.2431, G Loss: 1.3205\n",
            "Epoch [51/100], Step [500/1875], D Loss: 1.1774, G Loss: 0.9480\n",
            "Epoch [51/100], Step [600/1875], D Loss: 1.1296, G Loss: 1.1153\n",
            "Epoch [51/100], Step [700/1875], D Loss: 1.1854, G Loss: 1.1033\n",
            "Epoch [51/100], Step [800/1875], D Loss: 1.0195, G Loss: 1.5624\n",
            "Epoch [51/100], Step [900/1875], D Loss: 1.0848, G Loss: 1.0940\n",
            "Epoch [51/100], Step [1000/1875], D Loss: 1.1084, G Loss: 1.2979\n",
            "Epoch [51/100], Step [1100/1875], D Loss: 1.1246, G Loss: 1.1478\n",
            "Epoch [51/100], Step [1200/1875], D Loss: 1.1197, G Loss: 1.1531\n",
            "Epoch [51/100], Step [1300/1875], D Loss: 1.1418, G Loss: 1.2852\n",
            "Epoch [51/100], Step [1400/1875], D Loss: 1.2012, G Loss: 1.0955\n",
            "Epoch [51/100], Step [1500/1875], D Loss: 1.1051, G Loss: 1.2207\n",
            "Epoch [51/100], Step [1600/1875], D Loss: 0.9241, G Loss: 1.3718\n",
            "Epoch [51/100], Step [1700/1875], D Loss: 1.0337, G Loss: 1.3553\n",
            "Epoch [51/100], Step [1800/1875], D Loss: 1.1307, G Loss: 0.9510\n",
            "Epoch [52/100], Step [100/1875], D Loss: 1.0094, G Loss: 1.2230\n",
            "Epoch [52/100], Step [200/1875], D Loss: 1.1450, G Loss: 1.5379\n",
            "Epoch [52/100], Step [300/1875], D Loss: 1.1439, G Loss: 1.0175\n",
            "Epoch [52/100], Step [400/1875], D Loss: 0.9687, G Loss: 1.2923\n",
            "Epoch [52/100], Step [500/1875], D Loss: 0.9346, G Loss: 1.7466\n",
            "Epoch [52/100], Step [600/1875], D Loss: 0.9456, G Loss: 1.0575\n",
            "Epoch [52/100], Step [700/1875], D Loss: 1.0660, G Loss: 1.0466\n",
            "Epoch [52/100], Step [800/1875], D Loss: 1.0782, G Loss: 1.1335\n",
            "Epoch [52/100], Step [900/1875], D Loss: 0.9979, G Loss: 1.1714\n",
            "Epoch [52/100], Step [1000/1875], D Loss: 1.0995, G Loss: 0.9218\n",
            "Epoch [52/100], Step [1100/1875], D Loss: 1.1403, G Loss: 1.0755\n",
            "Epoch [52/100], Step [1200/1875], D Loss: 1.3081, G Loss: 1.2033\n",
            "Epoch [52/100], Step [1300/1875], D Loss: 1.1427, G Loss: 1.4605\n",
            "Epoch [52/100], Step [1400/1875], D Loss: 1.0766, G Loss: 1.1607\n",
            "Epoch [52/100], Step [1500/1875], D Loss: 0.9312, G Loss: 1.0293\n",
            "Epoch [52/100], Step [1600/1875], D Loss: 1.1635, G Loss: 1.1728\n",
            "Epoch [52/100], Step [1700/1875], D Loss: 0.9815, G Loss: 1.3350\n",
            "Epoch [52/100], Step [1800/1875], D Loss: 1.0533, G Loss: 1.2527\n",
            "Epoch [53/100], Step [100/1875], D Loss: 1.2509, G Loss: 1.1132\n",
            "Epoch [53/100], Step [200/1875], D Loss: 1.2583, G Loss: 0.9604\n",
            "Epoch [53/100], Step [300/1875], D Loss: 1.2565, G Loss: 1.0298\n",
            "Epoch [53/100], Step [400/1875], D Loss: 1.0256, G Loss: 1.0385\n",
            "Epoch [53/100], Step [500/1875], D Loss: 1.1994, G Loss: 1.0032\n",
            "Epoch [53/100], Step [600/1875], D Loss: 1.1134, G Loss: 1.1613\n",
            "Epoch [53/100], Step [700/1875], D Loss: 0.9683, G Loss: 1.3808\n",
            "Epoch [53/100], Step [800/1875], D Loss: 1.1888, G Loss: 1.3084\n",
            "Epoch [53/100], Step [900/1875], D Loss: 1.1421, G Loss: 1.1321\n",
            "Epoch [53/100], Step [1000/1875], D Loss: 1.1297, G Loss: 1.2196\n",
            "Epoch [53/100], Step [1100/1875], D Loss: 1.0220, G Loss: 1.1481\n",
            "Epoch [53/100], Step [1200/1875], D Loss: 1.1169, G Loss: 1.2709\n",
            "Epoch [53/100], Step [1300/1875], D Loss: 1.1556, G Loss: 1.1196\n",
            "Epoch [53/100], Step [1400/1875], D Loss: 1.1926, G Loss: 0.9518\n",
            "Epoch [53/100], Step [1500/1875], D Loss: 1.0011, G Loss: 1.2771\n",
            "Epoch [53/100], Step [1600/1875], D Loss: 0.9745, G Loss: 1.1799\n",
            "Epoch [53/100], Step [1700/1875], D Loss: 1.1101, G Loss: 1.1993\n",
            "Epoch [53/100], Step [1800/1875], D Loss: 1.0807, G Loss: 1.1847\n",
            "Epoch [54/100], Step [100/1875], D Loss: 1.0830, G Loss: 1.2751\n",
            "Epoch [54/100], Step [200/1875], D Loss: 1.0938, G Loss: 1.2938\n",
            "Epoch [54/100], Step [300/1875], D Loss: 1.2565, G Loss: 0.9774\n",
            "Epoch [54/100], Step [400/1875], D Loss: 1.2688, G Loss: 0.8406\n",
            "Epoch [54/100], Step [500/1875], D Loss: 1.1318, G Loss: 1.0335\n",
            "Epoch [54/100], Step [600/1875], D Loss: 0.8673, G Loss: 1.4388\n",
            "Epoch [54/100], Step [700/1875], D Loss: 1.0207, G Loss: 1.3919\n",
            "Epoch [54/100], Step [800/1875], D Loss: 1.0708, G Loss: 1.2793\n",
            "Epoch [54/100], Step [900/1875], D Loss: 1.0554, G Loss: 1.2334\n",
            "Epoch [54/100], Step [1000/1875], D Loss: 0.8608, G Loss: 1.4254\n",
            "Epoch [54/100], Step [1100/1875], D Loss: 1.1011, G Loss: 1.3271\n",
            "Epoch [54/100], Step [1200/1875], D Loss: 1.2622, G Loss: 1.0738\n",
            "Epoch [54/100], Step [1300/1875], D Loss: 1.2264, G Loss: 1.1449\n",
            "Epoch [54/100], Step [1400/1875], D Loss: 1.2067, G Loss: 1.1020\n",
            "Epoch [54/100], Step [1500/1875], D Loss: 1.1376, G Loss: 1.0599\n",
            "Epoch [54/100], Step [1600/1875], D Loss: 1.0490, G Loss: 1.3469\n",
            "Epoch [54/100], Step [1700/1875], D Loss: 1.1655, G Loss: 1.2457\n",
            "Epoch [54/100], Step [1800/1875], D Loss: 1.0834, G Loss: 1.0955\n",
            "Epoch [55/100], Step [100/1875], D Loss: 1.2010, G Loss: 1.2302\n",
            "Epoch [55/100], Step [200/1875], D Loss: 1.1977, G Loss: 0.7856\n",
            "Epoch [55/100], Step [300/1875], D Loss: 1.1096, G Loss: 1.1779\n",
            "Epoch [55/100], Step [400/1875], D Loss: 1.0100, G Loss: 1.0835\n",
            "Epoch [55/100], Step [500/1875], D Loss: 1.0838, G Loss: 1.1140\n",
            "Epoch [55/100], Step [600/1875], D Loss: 1.2346, G Loss: 0.8867\n",
            "Epoch [55/100], Step [700/1875], D Loss: 1.1629, G Loss: 1.2504\n",
            "Epoch [55/100], Step [800/1875], D Loss: 0.8551, G Loss: 1.3806\n",
            "Epoch [55/100], Step [900/1875], D Loss: 1.2252, G Loss: 1.0907\n",
            "Epoch [55/100], Step [1000/1875], D Loss: 1.1194, G Loss: 1.2511\n",
            "Epoch [55/100], Step [1100/1875], D Loss: 1.1728, G Loss: 1.3627\n",
            "Epoch [55/100], Step [1200/1875], D Loss: 1.0797, G Loss: 1.1475\n",
            "Epoch [55/100], Step [1300/1875], D Loss: 0.9951, G Loss: 1.2402\n",
            "Epoch [55/100], Step [1400/1875], D Loss: 1.0182, G Loss: 1.1886\n",
            "Epoch [55/100], Step [1500/1875], D Loss: 1.1104, G Loss: 1.2634\n",
            "Epoch [55/100], Step [1600/1875], D Loss: 1.2159, G Loss: 1.2867\n",
            "Epoch [55/100], Step [1700/1875], D Loss: 1.2940, G Loss: 0.9185\n",
            "Epoch [55/100], Step [1800/1875], D Loss: 1.1936, G Loss: 0.8356\n",
            "Epoch [56/100], Step [100/1875], D Loss: 1.0684, G Loss: 1.4473\n",
            "Epoch [56/100], Step [200/1875], D Loss: 0.9428, G Loss: 1.2469\n",
            "Epoch [56/100], Step [300/1875], D Loss: 0.9806, G Loss: 1.4101\n",
            "Epoch [56/100], Step [400/1875], D Loss: 1.2568, G Loss: 1.1603\n",
            "Epoch [56/100], Step [500/1875], D Loss: 1.4451, G Loss: 0.9466\n",
            "Epoch [56/100], Step [600/1875], D Loss: 1.1274, G Loss: 1.1400\n",
            "Epoch [56/100], Step [700/1875], D Loss: 0.9676, G Loss: 1.1601\n",
            "Epoch [56/100], Step [800/1875], D Loss: 0.9123, G Loss: 1.1693\n",
            "Epoch [56/100], Step [900/1875], D Loss: 1.3496, G Loss: 1.1725\n",
            "Epoch [56/100], Step [1000/1875], D Loss: 1.2995, G Loss: 0.9044\n",
            "Epoch [56/100], Step [1100/1875], D Loss: 1.0434, G Loss: 1.3412\n",
            "Epoch [56/100], Step [1200/1875], D Loss: 1.2592, G Loss: 0.9627\n",
            "Epoch [56/100], Step [1300/1875], D Loss: 1.0562, G Loss: 1.3831\n",
            "Epoch [56/100], Step [1400/1875], D Loss: 1.2101, G Loss: 1.2893\n",
            "Epoch [56/100], Step [1500/1875], D Loss: 1.2534, G Loss: 1.3275\n",
            "Epoch [56/100], Step [1600/1875], D Loss: 1.1717, G Loss: 0.8986\n",
            "Epoch [56/100], Step [1700/1875], D Loss: 1.1096, G Loss: 1.4710\n",
            "Epoch [56/100], Step [1800/1875], D Loss: 1.0530, G Loss: 1.2677\n",
            "Epoch [57/100], Step [100/1875], D Loss: 1.5554, G Loss: 0.7270\n",
            "Epoch [57/100], Step [200/1875], D Loss: 1.2786, G Loss: 0.8976\n",
            "Epoch [57/100], Step [300/1875], D Loss: 1.0993, G Loss: 1.0221\n",
            "Epoch [57/100], Step [400/1875], D Loss: 1.1748, G Loss: 1.1577\n",
            "Epoch [57/100], Step [500/1875], D Loss: 1.2120, G Loss: 1.0543\n",
            "Epoch [57/100], Step [600/1875], D Loss: 1.2467, G Loss: 0.8541\n",
            "Epoch [57/100], Step [700/1875], D Loss: 0.9877, G Loss: 1.0820\n",
            "Epoch [57/100], Step [800/1875], D Loss: 1.0302, G Loss: 1.1390\n",
            "Epoch [57/100], Step [900/1875], D Loss: 1.1789, G Loss: 0.9083\n",
            "Epoch [57/100], Step [1000/1875], D Loss: 1.0185, G Loss: 1.2547\n",
            "Epoch [57/100], Step [1100/1875], D Loss: 1.0728, G Loss: 1.0729\n",
            "Epoch [57/100], Step [1200/1875], D Loss: 1.3078, G Loss: 0.9001\n",
            "Epoch [57/100], Step [1300/1875], D Loss: 1.0960, G Loss: 1.1625\n",
            "Epoch [57/100], Step [1400/1875], D Loss: 1.1067, G Loss: 1.1761\n",
            "Epoch [57/100], Step [1500/1875], D Loss: 1.2649, G Loss: 1.3173\n",
            "Epoch [57/100], Step [1600/1875], D Loss: 1.0690, G Loss: 1.0797\n",
            "Epoch [57/100], Step [1700/1875], D Loss: 1.4292, G Loss: 0.9522\n",
            "Epoch [57/100], Step [1800/1875], D Loss: 1.2448, G Loss: 1.1087\n",
            "Epoch [58/100], Step [100/1875], D Loss: 0.9834, G Loss: 1.1941\n",
            "Epoch [58/100], Step [200/1875], D Loss: 1.1198, G Loss: 1.1030\n",
            "Epoch [58/100], Step [300/1875], D Loss: 1.3351, G Loss: 1.1926\n",
            "Epoch [58/100], Step [400/1875], D Loss: 1.1811, G Loss: 1.0032\n",
            "Epoch [58/100], Step [500/1875], D Loss: 1.2100, G Loss: 1.1440\n",
            "Epoch [58/100], Step [600/1875], D Loss: 1.1825, G Loss: 0.8761\n",
            "Epoch [58/100], Step [700/1875], D Loss: 1.2157, G Loss: 1.2660\n",
            "Epoch [58/100], Step [800/1875], D Loss: 1.2655, G Loss: 1.2415\n",
            "Epoch [58/100], Step [900/1875], D Loss: 1.1591, G Loss: 0.9612\n",
            "Epoch [58/100], Step [1000/1875], D Loss: 1.2625, G Loss: 1.1693\n",
            "Epoch [58/100], Step [1100/1875], D Loss: 1.1423, G Loss: 1.2658\n",
            "Epoch [58/100], Step [1200/1875], D Loss: 1.1639, G Loss: 1.3646\n",
            "Epoch [58/100], Step [1300/1875], D Loss: 1.2868, G Loss: 1.1642\n",
            "Epoch [58/100], Step [1400/1875], D Loss: 1.1323, G Loss: 1.0141\n",
            "Epoch [58/100], Step [1500/1875], D Loss: 1.0243, G Loss: 1.0656\n",
            "Epoch [58/100], Step [1600/1875], D Loss: 1.2515, G Loss: 1.4265\n",
            "Epoch [58/100], Step [1700/1875], D Loss: 1.2679, G Loss: 1.2414\n",
            "Epoch [58/100], Step [1800/1875], D Loss: 1.2235, G Loss: 1.2757\n",
            "Epoch [59/100], Step [100/1875], D Loss: 1.3316, G Loss: 1.4314\n",
            "Epoch [59/100], Step [200/1875], D Loss: 1.1495, G Loss: 1.1406\n",
            "Epoch [59/100], Step [300/1875], D Loss: 1.2206, G Loss: 0.8774\n",
            "Epoch [59/100], Step [400/1875], D Loss: 1.2689, G Loss: 1.0114\n",
            "Epoch [59/100], Step [500/1875], D Loss: 1.1456, G Loss: 0.9019\n",
            "Epoch [59/100], Step [600/1875], D Loss: 1.0932, G Loss: 1.2280\n",
            "Epoch [59/100], Step [700/1875], D Loss: 1.1110, G Loss: 0.9221\n",
            "Epoch [59/100], Step [800/1875], D Loss: 1.0085, G Loss: 1.1567\n",
            "Epoch [59/100], Step [900/1875], D Loss: 1.2188, G Loss: 1.1861\n",
            "Epoch [59/100], Step [1000/1875], D Loss: 1.0636, G Loss: 1.1674\n",
            "Epoch [59/100], Step [1100/1875], D Loss: 1.2844, G Loss: 1.2363\n",
            "Epoch [59/100], Step [1200/1875], D Loss: 1.0472, G Loss: 1.1296\n",
            "Epoch [59/100], Step [1300/1875], D Loss: 1.0505, G Loss: 1.2346\n",
            "Epoch [59/100], Step [1400/1875], D Loss: 1.2308, G Loss: 1.0755\n",
            "Epoch [59/100], Step [1500/1875], D Loss: 1.0540, G Loss: 1.2865\n",
            "Epoch [59/100], Step [1600/1875], D Loss: 0.9698, G Loss: 1.2759\n",
            "Epoch [59/100], Step [1700/1875], D Loss: 0.8971, G Loss: 1.2372\n",
            "Epoch [59/100], Step [1800/1875], D Loss: 1.1551, G Loss: 1.0179\n",
            "Epoch [60/100], Step [100/1875], D Loss: 1.2400, G Loss: 1.0250\n",
            "Epoch [60/100], Step [200/1875], D Loss: 1.2065, G Loss: 1.1416\n",
            "Epoch [60/100], Step [300/1875], D Loss: 1.0907, G Loss: 1.1655\n",
            "Epoch [60/100], Step [400/1875], D Loss: 1.2642, G Loss: 1.5519\n",
            "Epoch [60/100], Step [500/1875], D Loss: 1.1448, G Loss: 1.3053\n",
            "Epoch [60/100], Step [600/1875], D Loss: 1.2499, G Loss: 0.9770\n",
            "Epoch [60/100], Step [700/1875], D Loss: 1.3362, G Loss: 1.3296\n",
            "Epoch [60/100], Step [800/1875], D Loss: 0.9821, G Loss: 1.2178\n",
            "Epoch [60/100], Step [900/1875], D Loss: 0.9986, G Loss: 1.1042\n",
            "Epoch [60/100], Step [1000/1875], D Loss: 1.1891, G Loss: 1.0003\n",
            "Epoch [60/100], Step [1100/1875], D Loss: 1.1349, G Loss: 1.0479\n",
            "Epoch [60/100], Step [1200/1875], D Loss: 1.2555, G Loss: 0.8382\n",
            "Epoch [60/100], Step [1300/1875], D Loss: 1.0316, G Loss: 1.0980\n",
            "Epoch [60/100], Step [1400/1875], D Loss: 1.0941, G Loss: 1.1081\n",
            "Epoch [60/100], Step [1500/1875], D Loss: 1.1131, G Loss: 1.0132\n",
            "Epoch [60/100], Step [1600/1875], D Loss: 1.0703, G Loss: 1.2887\n",
            "Epoch [60/100], Step [1700/1875], D Loss: 1.0957, G Loss: 1.1957\n",
            "Epoch [60/100], Step [1800/1875], D Loss: 1.2508, G Loss: 1.4003\n",
            "Epoch [61/100], Step [100/1875], D Loss: 1.3372, G Loss: 1.0063\n",
            "Epoch [61/100], Step [200/1875], D Loss: 0.9437, G Loss: 1.3224\n",
            "Epoch [61/100], Step [300/1875], D Loss: 0.9780, G Loss: 1.3472\n",
            "Epoch [61/100], Step [400/1875], D Loss: 0.9632, G Loss: 1.3406\n",
            "Epoch [61/100], Step [500/1875], D Loss: 1.0677, G Loss: 1.2078\n",
            "Epoch [61/100], Step [600/1875], D Loss: 1.0997, G Loss: 1.1717\n",
            "Epoch [61/100], Step [700/1875], D Loss: 1.2007, G Loss: 1.0392\n",
            "Epoch [61/100], Step [800/1875], D Loss: 1.2462, G Loss: 1.4114\n",
            "Epoch [61/100], Step [900/1875], D Loss: 1.1734, G Loss: 1.1352\n",
            "Epoch [61/100], Step [1000/1875], D Loss: 1.1335, G Loss: 1.0939\n",
            "Epoch [61/100], Step [1100/1875], D Loss: 1.0252, G Loss: 1.1136\n",
            "Epoch [61/100], Step [1200/1875], D Loss: 1.6259, G Loss: 0.9121\n",
            "Epoch [61/100], Step [1300/1875], D Loss: 0.9759, G Loss: 1.1127\n",
            "Epoch [61/100], Step [1400/1875], D Loss: 1.0418, G Loss: 1.0874\n",
            "Epoch [61/100], Step [1500/1875], D Loss: 0.9085, G Loss: 1.3683\n",
            "Epoch [61/100], Step [1600/1875], D Loss: 1.3107, G Loss: 1.1545\n",
            "Epoch [61/100], Step [1700/1875], D Loss: 1.1688, G Loss: 0.8699\n",
            "Epoch [61/100], Step [1800/1875], D Loss: 1.0848, G Loss: 1.2754\n",
            "Epoch [62/100], Step [100/1875], D Loss: 1.2884, G Loss: 0.7287\n",
            "Epoch [62/100], Step [200/1875], D Loss: 0.9863, G Loss: 1.1674\n",
            "Epoch [62/100], Step [300/1875], D Loss: 1.0873, G Loss: 1.2608\n",
            "Epoch [62/100], Step [400/1875], D Loss: 1.1254, G Loss: 1.3149\n",
            "Epoch [62/100], Step [500/1875], D Loss: 0.9521, G Loss: 1.3987\n",
            "Epoch [62/100], Step [600/1875], D Loss: 1.2181, G Loss: 1.2554\n",
            "Epoch [62/100], Step [700/1875], D Loss: 1.1088, G Loss: 1.0063\n",
            "Epoch [62/100], Step [800/1875], D Loss: 1.3023, G Loss: 1.1239\n",
            "Epoch [62/100], Step [900/1875], D Loss: 1.3423, G Loss: 0.8308\n",
            "Epoch [62/100], Step [1000/1875], D Loss: 1.1229, G Loss: 0.9942\n",
            "Epoch [62/100], Step [1100/1875], D Loss: 1.0980, G Loss: 1.0649\n",
            "Epoch [62/100], Step [1200/1875], D Loss: 1.1475, G Loss: 0.9306\n",
            "Epoch [62/100], Step [1300/1875], D Loss: 1.2606, G Loss: 1.0143\n",
            "Epoch [62/100], Step [1400/1875], D Loss: 1.0897, G Loss: 1.4490\n",
            "Epoch [62/100], Step [1500/1875], D Loss: 0.9650, G Loss: 1.1754\n",
            "Epoch [62/100], Step [1600/1875], D Loss: 1.1398, G Loss: 0.9739\n",
            "Epoch [62/100], Step [1700/1875], D Loss: 1.0533, G Loss: 1.0981\n",
            "Epoch [62/100], Step [1800/1875], D Loss: 1.3324, G Loss: 1.0546\n",
            "Epoch [63/100], Step [100/1875], D Loss: 1.0056, G Loss: 1.2726\n",
            "Epoch [63/100], Step [200/1875], D Loss: 1.2374, G Loss: 0.6893\n",
            "Epoch [63/100], Step [300/1875], D Loss: 1.1228, G Loss: 1.0682\n",
            "Epoch [63/100], Step [400/1875], D Loss: 1.0848, G Loss: 1.0648\n",
            "Epoch [63/100], Step [500/1875], D Loss: 1.1221, G Loss: 1.0383\n",
            "Epoch [63/100], Step [600/1875], D Loss: 1.1571, G Loss: 1.1383\n",
            "Epoch [63/100], Step [700/1875], D Loss: 1.1057, G Loss: 1.2174\n",
            "Epoch [63/100], Step [800/1875], D Loss: 1.0576, G Loss: 1.1828\n",
            "Epoch [63/100], Step [900/1875], D Loss: 1.0444, G Loss: 1.0453\n",
            "Epoch [63/100], Step [1000/1875], D Loss: 1.1558, G Loss: 0.8773\n",
            "Epoch [63/100], Step [1100/1875], D Loss: 1.3550, G Loss: 0.9349\n",
            "Epoch [63/100], Step [1200/1875], D Loss: 1.0509, G Loss: 1.3737\n",
            "Epoch [63/100], Step [1300/1875], D Loss: 1.0896, G Loss: 1.2319\n",
            "Epoch [63/100], Step [1400/1875], D Loss: 0.9159, G Loss: 0.9638\n",
            "Epoch [63/100], Step [1500/1875], D Loss: 1.2348, G Loss: 1.0801\n",
            "Epoch [63/100], Step [1600/1875], D Loss: 1.2198, G Loss: 1.0581\n",
            "Epoch [63/100], Step [1700/1875], D Loss: 1.2304, G Loss: 1.0470\n",
            "Epoch [63/100], Step [1800/1875], D Loss: 1.2304, G Loss: 1.0852\n",
            "Epoch [64/100], Step [100/1875], D Loss: 1.1263, G Loss: 1.1102\n",
            "Epoch [64/100], Step [200/1875], D Loss: 1.2548, G Loss: 1.0741\n",
            "Epoch [64/100], Step [300/1875], D Loss: 1.1760, G Loss: 1.1957\n",
            "Epoch [64/100], Step [400/1875], D Loss: 1.2598, G Loss: 0.9337\n",
            "Epoch [64/100], Step [500/1875], D Loss: 1.1150, G Loss: 1.1760\n",
            "Epoch [64/100], Step [600/1875], D Loss: 1.1812, G Loss: 1.2556\n",
            "Epoch [64/100], Step [700/1875], D Loss: 1.1119, G Loss: 1.1346\n",
            "Epoch [64/100], Step [800/1875], D Loss: 1.2811, G Loss: 0.9153\n",
            "Epoch [64/100], Step [900/1875], D Loss: 1.1063, G Loss: 0.9243\n",
            "Epoch [64/100], Step [1000/1875], D Loss: 1.4651, G Loss: 0.9223\n",
            "Epoch [64/100], Step [1100/1875], D Loss: 1.1856, G Loss: 0.9141\n",
            "Epoch [64/100], Step [1200/1875], D Loss: 1.3163, G Loss: 1.0262\n",
            "Epoch [64/100], Step [1300/1875], D Loss: 1.2054, G Loss: 1.1735\n",
            "Epoch [64/100], Step [1400/1875], D Loss: 1.2056, G Loss: 1.0227\n",
            "Epoch [64/100], Step [1500/1875], D Loss: 1.0204, G Loss: 1.2834\n",
            "Epoch [64/100], Step [1600/1875], D Loss: 1.1307, G Loss: 1.0796\n",
            "Epoch [64/100], Step [1700/1875], D Loss: 1.1010, G Loss: 1.3522\n",
            "Epoch [64/100], Step [1800/1875], D Loss: 1.2180, G Loss: 1.2827\n",
            "Epoch [65/100], Step [100/1875], D Loss: 1.2806, G Loss: 1.0500\n",
            "Epoch [65/100], Step [200/1875], D Loss: 1.1548, G Loss: 0.8793\n",
            "Epoch [65/100], Step [300/1875], D Loss: 1.0407, G Loss: 1.4358\n",
            "Epoch [65/100], Step [400/1875], D Loss: 0.9265, G Loss: 1.5688\n",
            "Epoch [65/100], Step [500/1875], D Loss: 1.0601, G Loss: 1.1770\n",
            "Epoch [65/100], Step [600/1875], D Loss: 1.0131, G Loss: 1.4819\n",
            "Epoch [65/100], Step [700/1875], D Loss: 1.1669, G Loss: 1.0565\n",
            "Epoch [65/100], Step [800/1875], D Loss: 0.9187, G Loss: 1.5823\n",
            "Epoch [65/100], Step [900/1875], D Loss: 1.0581, G Loss: 1.0213\n",
            "Epoch [65/100], Step [1000/1875], D Loss: 1.1309, G Loss: 0.9627\n",
            "Epoch [65/100], Step [1100/1875], D Loss: 1.2663, G Loss: 0.9812\n",
            "Epoch [65/100], Step [1200/1875], D Loss: 1.3393, G Loss: 0.8971\n",
            "Epoch [65/100], Step [1300/1875], D Loss: 1.5372, G Loss: 0.7565\n",
            "Epoch [65/100], Step [1400/1875], D Loss: 1.3937, G Loss: 0.9689\n",
            "Epoch [65/100], Step [1500/1875], D Loss: 1.3353, G Loss: 0.9685\n",
            "Epoch [65/100], Step [1600/1875], D Loss: 1.3300, G Loss: 1.0712\n",
            "Epoch [65/100], Step [1700/1875], D Loss: 1.1270, G Loss: 1.0724\n",
            "Epoch [65/100], Step [1800/1875], D Loss: 1.1660, G Loss: 0.8308\n",
            "Epoch [66/100], Step [100/1875], D Loss: 1.1751, G Loss: 1.0729\n",
            "Epoch [66/100], Step [200/1875], D Loss: 1.1615, G Loss: 1.1946\n",
            "Epoch [66/100], Step [300/1875], D Loss: 1.1001, G Loss: 1.1007\n",
            "Epoch [66/100], Step [400/1875], D Loss: 1.1477, G Loss: 1.1219\n",
            "Epoch [66/100], Step [500/1875], D Loss: 1.1716, G Loss: 1.3625\n",
            "Epoch [66/100], Step [600/1875], D Loss: 1.3201, G Loss: 0.8566\n",
            "Epoch [66/100], Step [700/1875], D Loss: 1.2589, G Loss: 1.2709\n",
            "Epoch [66/100], Step [800/1875], D Loss: 1.1967, G Loss: 1.0960\n",
            "Epoch [66/100], Step [900/1875], D Loss: 1.1748, G Loss: 1.3528\n",
            "Epoch [66/100], Step [1000/1875], D Loss: 1.2228, G Loss: 0.9092\n",
            "Epoch [66/100], Step [1100/1875], D Loss: 1.1830, G Loss: 0.8974\n",
            "Epoch [66/100], Step [1200/1875], D Loss: 1.1171, G Loss: 0.9479\n",
            "Epoch [66/100], Step [1300/1875], D Loss: 1.0632, G Loss: 1.3199\n",
            "Epoch [66/100], Step [1400/1875], D Loss: 1.1569, G Loss: 1.0865\n",
            "Epoch [66/100], Step [1500/1875], D Loss: 1.2104, G Loss: 1.3045\n",
            "Epoch [66/100], Step [1600/1875], D Loss: 1.2352, G Loss: 1.1544\n",
            "Epoch [66/100], Step [1700/1875], D Loss: 1.2241, G Loss: 1.0737\n",
            "Epoch [66/100], Step [1800/1875], D Loss: 1.2866, G Loss: 1.2527\n",
            "Epoch [67/100], Step [100/1875], D Loss: 0.9787, G Loss: 1.3176\n",
            "Epoch [67/100], Step [200/1875], D Loss: 1.2350, G Loss: 0.8522\n",
            "Epoch [67/100], Step [300/1875], D Loss: 1.1497, G Loss: 1.2879\n",
            "Epoch [67/100], Step [400/1875], D Loss: 1.1834, G Loss: 1.1172\n",
            "Epoch [67/100], Step [500/1875], D Loss: 1.2882, G Loss: 0.9681\n",
            "Epoch [67/100], Step [600/1875], D Loss: 1.1199, G Loss: 1.3278\n",
            "Epoch [67/100], Step [700/1875], D Loss: 1.2294, G Loss: 1.1275\n",
            "Epoch [67/100], Step [800/1875], D Loss: 1.0797, G Loss: 0.9606\n",
            "Epoch [67/100], Step [900/1875], D Loss: 1.3094, G Loss: 1.0538\n",
            "Epoch [67/100], Step [1000/1875], D Loss: 1.0946, G Loss: 1.0507\n",
            "Epoch [67/100], Step [1100/1875], D Loss: 1.1372, G Loss: 0.9488\n",
            "Epoch [67/100], Step [1200/1875], D Loss: 1.0143, G Loss: 1.1274\n",
            "Epoch [67/100], Step [1300/1875], D Loss: 1.4986, G Loss: 1.3628\n",
            "Epoch [67/100], Step [1400/1875], D Loss: 1.0784, G Loss: 0.8750\n",
            "Epoch [67/100], Step [1500/1875], D Loss: 0.9987, G Loss: 0.8460\n",
            "Epoch [67/100], Step [1600/1875], D Loss: 1.3429, G Loss: 0.7656\n",
            "Epoch [67/100], Step [1700/1875], D Loss: 1.2627, G Loss: 1.2765\n",
            "Epoch [67/100], Step [1800/1875], D Loss: 1.1725, G Loss: 0.9761\n",
            "Epoch [68/100], Step [100/1875], D Loss: 1.1296, G Loss: 1.0977\n",
            "Epoch [68/100], Step [200/1875], D Loss: 0.9783, G Loss: 1.1636\n",
            "Epoch [68/100], Step [300/1875], D Loss: 0.9978, G Loss: 1.3829\n",
            "Epoch [68/100], Step [400/1875], D Loss: 1.2551, G Loss: 1.0413\n",
            "Epoch [68/100], Step [500/1875], D Loss: 1.2392, G Loss: 1.0817\n",
            "Epoch [68/100], Step [600/1875], D Loss: 1.2918, G Loss: 1.0250\n",
            "Epoch [68/100], Step [700/1875], D Loss: 1.2160, G Loss: 1.0755\n",
            "Epoch [68/100], Step [800/1875], D Loss: 1.2383, G Loss: 1.2139\n",
            "Epoch [68/100], Step [900/1875], D Loss: 1.3018, G Loss: 1.1135\n",
            "Epoch [68/100], Step [1000/1875], D Loss: 1.0955, G Loss: 1.3872\n",
            "Epoch [68/100], Step [1100/1875], D Loss: 1.1253, G Loss: 1.0873\n",
            "Epoch [68/100], Step [1200/1875], D Loss: 1.2091, G Loss: 1.1053\n",
            "Epoch [68/100], Step [1300/1875], D Loss: 1.1662, G Loss: 0.9378\n",
            "Epoch [68/100], Step [1400/1875], D Loss: 1.1099, G Loss: 0.9839\n",
            "Epoch [68/100], Step [1500/1875], D Loss: 1.0849, G Loss: 1.4037\n",
            "Epoch [68/100], Step [1600/1875], D Loss: 1.0374, G Loss: 1.2040\n",
            "Epoch [68/100], Step [1700/1875], D Loss: 1.1842, G Loss: 0.7664\n",
            "Epoch [68/100], Step [1800/1875], D Loss: 1.0472, G Loss: 0.9997\n",
            "Epoch [69/100], Step [100/1875], D Loss: 1.2928, G Loss: 1.0196\n",
            "Epoch [69/100], Step [200/1875], D Loss: 0.9120, G Loss: 1.2265\n",
            "Epoch [69/100], Step [300/1875], D Loss: 1.1911, G Loss: 1.0500\n",
            "Epoch [69/100], Step [400/1875], D Loss: 1.3140, G Loss: 0.9509\n",
            "Epoch [69/100], Step [500/1875], D Loss: 1.1206, G Loss: 0.8844\n",
            "Epoch [69/100], Step [600/1875], D Loss: 1.2167, G Loss: 1.1483\n",
            "Epoch [69/100], Step [700/1875], D Loss: 1.3619, G Loss: 1.0485\n",
            "Epoch [69/100], Step [800/1875], D Loss: 1.2174, G Loss: 0.8914\n",
            "Epoch [69/100], Step [900/1875], D Loss: 1.1882, G Loss: 1.4114\n",
            "Epoch [69/100], Step [1000/1875], D Loss: 1.1699, G Loss: 1.0309\n",
            "Epoch [69/100], Step [1100/1875], D Loss: 1.0779, G Loss: 0.9303\n",
            "Epoch [69/100], Step [1200/1875], D Loss: 1.1582, G Loss: 1.3628\n",
            "Epoch [69/100], Step [1300/1875], D Loss: 1.4394, G Loss: 0.9258\n",
            "Epoch [69/100], Step [1400/1875], D Loss: 1.3299, G Loss: 1.0473\n",
            "Epoch [69/100], Step [1500/1875], D Loss: 1.0368, G Loss: 1.0273\n",
            "Epoch [69/100], Step [1600/1875], D Loss: 1.1064, G Loss: 1.1132\n",
            "Epoch [69/100], Step [1700/1875], D Loss: 1.1329, G Loss: 1.2528\n",
            "Epoch [69/100], Step [1800/1875], D Loss: 1.1825, G Loss: 1.0044\n",
            "Epoch [70/100], Step [100/1875], D Loss: 1.0368, G Loss: 1.0812\n",
            "Epoch [70/100], Step [200/1875], D Loss: 1.4539, G Loss: 0.6545\n",
            "Epoch [70/100], Step [300/1875], D Loss: 1.0215, G Loss: 1.3810\n",
            "Epoch [70/100], Step [400/1875], D Loss: 1.2139, G Loss: 0.9690\n",
            "Epoch [70/100], Step [500/1875], D Loss: 1.0687, G Loss: 1.1263\n",
            "Epoch [70/100], Step [600/1875], D Loss: 1.1032, G Loss: 1.1248\n",
            "Epoch [70/100], Step [700/1875], D Loss: 1.2223, G Loss: 0.8988\n",
            "Epoch [70/100], Step [800/1875], D Loss: 1.2611, G Loss: 1.1867\n",
            "Epoch [70/100], Step [900/1875], D Loss: 1.2694, G Loss: 1.0744\n",
            "Epoch [70/100], Step [1000/1875], D Loss: 0.9669, G Loss: 1.0501\n",
            "Epoch [70/100], Step [1100/1875], D Loss: 1.2879, G Loss: 0.9829\n",
            "Epoch [70/100], Step [1200/1875], D Loss: 1.1687, G Loss: 0.8604\n",
            "Epoch [70/100], Step [1300/1875], D Loss: 1.4163, G Loss: 0.8852\n",
            "Epoch [70/100], Step [1400/1875], D Loss: 1.0833, G Loss: 1.1236\n",
            "Epoch [70/100], Step [1500/1875], D Loss: 1.3158, G Loss: 0.7933\n",
            "Epoch [70/100], Step [1600/1875], D Loss: 1.3877, G Loss: 0.8410\n",
            "Epoch [70/100], Step [1700/1875], D Loss: 1.4517, G Loss: 1.0104\n",
            "Epoch [70/100], Step [1800/1875], D Loss: 1.2647, G Loss: 0.8430\n",
            "Epoch [71/100], Step [100/1875], D Loss: 1.2184, G Loss: 1.1589\n",
            "Epoch [71/100], Step [200/1875], D Loss: 1.1102, G Loss: 1.1232\n",
            "Epoch [71/100], Step [300/1875], D Loss: 1.2130, G Loss: 0.7920\n",
            "Epoch [71/100], Step [400/1875], D Loss: 1.0303, G Loss: 1.2247\n",
            "Epoch [71/100], Step [500/1875], D Loss: 1.1398, G Loss: 1.2306\n",
            "Epoch [71/100], Step [600/1875], D Loss: 1.0509, G Loss: 1.0330\n",
            "Epoch [71/100], Step [700/1875], D Loss: 0.9874, G Loss: 1.2701\n",
            "Epoch [71/100], Step [800/1875], D Loss: 1.0017, G Loss: 1.2477\n",
            "Epoch [71/100], Step [900/1875], D Loss: 1.1436, G Loss: 0.9101\n",
            "Epoch [71/100], Step [1000/1875], D Loss: 1.3348, G Loss: 0.9487\n",
            "Epoch [71/100], Step [1100/1875], D Loss: 1.3678, G Loss: 0.8254\n",
            "Epoch [71/100], Step [1200/1875], D Loss: 1.1937, G Loss: 1.2190\n",
            "Epoch [71/100], Step [1300/1875], D Loss: 1.1372, G Loss: 1.1347\n",
            "Epoch [71/100], Step [1400/1875], D Loss: 1.0462, G Loss: 1.1698\n",
            "Epoch [71/100], Step [1500/1875], D Loss: 1.2825, G Loss: 0.9709\n",
            "Epoch [71/100], Step [1600/1875], D Loss: 1.2273, G Loss: 1.2379\n",
            "Epoch [71/100], Step [1700/1875], D Loss: 1.0962, G Loss: 0.9859\n",
            "Epoch [71/100], Step [1800/1875], D Loss: 1.1765, G Loss: 1.1902\n",
            "Epoch [72/100], Step [100/1875], D Loss: 0.9916, G Loss: 1.0578\n",
            "Epoch [72/100], Step [200/1875], D Loss: 1.2719, G Loss: 0.9540\n",
            "Epoch [72/100], Step [300/1875], D Loss: 1.0730, G Loss: 1.4585\n",
            "Epoch [72/100], Step [400/1875], D Loss: 0.9811, G Loss: 0.9888\n",
            "Epoch [72/100], Step [500/1875], D Loss: 1.2334, G Loss: 1.2801\n",
            "Epoch [72/100], Step [600/1875], D Loss: 1.0270, G Loss: 0.9880\n",
            "Epoch [72/100], Step [700/1875], D Loss: 1.2430, G Loss: 0.9245\n",
            "Epoch [72/100], Step [800/1875], D Loss: 1.1802, G Loss: 1.0738\n",
            "Epoch [72/100], Step [900/1875], D Loss: 1.2039, G Loss: 0.9865\n",
            "Epoch [72/100], Step [1000/1875], D Loss: 1.0412, G Loss: 1.0863\n",
            "Epoch [72/100], Step [1100/1875], D Loss: 1.1872, G Loss: 0.8574\n",
            "Epoch [72/100], Step [1200/1875], D Loss: 1.2223, G Loss: 0.8620\n",
            "Epoch [72/100], Step [1300/1875], D Loss: 1.1270, G Loss: 0.8393\n",
            "Epoch [72/100], Step [1400/1875], D Loss: 1.1490, G Loss: 1.1606\n",
            "Epoch [72/100], Step [1500/1875], D Loss: 0.9702, G Loss: 1.3230\n",
            "Epoch [72/100], Step [1600/1875], D Loss: 1.1615, G Loss: 0.9547\n",
            "Epoch [72/100], Step [1700/1875], D Loss: 1.2124, G Loss: 1.0156\n",
            "Epoch [72/100], Step [1800/1875], D Loss: 1.1017, G Loss: 1.1664\n",
            "Epoch [73/100], Step [100/1875], D Loss: 1.2990, G Loss: 0.9474\n",
            "Epoch [73/100], Step [200/1875], D Loss: 1.0288, G Loss: 1.0508\n",
            "Epoch [73/100], Step [300/1875], D Loss: 1.1760, G Loss: 1.1268\n",
            "Epoch [73/100], Step [400/1875], D Loss: 1.0980, G Loss: 0.8414\n",
            "Epoch [73/100], Step [500/1875], D Loss: 1.1607, G Loss: 1.0089\n",
            "Epoch [73/100], Step [600/1875], D Loss: 1.3494, G Loss: 1.4774\n",
            "Epoch [73/100], Step [700/1875], D Loss: 1.2100, G Loss: 1.1545\n",
            "Epoch [73/100], Step [800/1875], D Loss: 1.0483, G Loss: 1.0199\n",
            "Epoch [73/100], Step [900/1875], D Loss: 1.2313, G Loss: 0.8598\n",
            "Epoch [73/100], Step [1000/1875], D Loss: 1.2082, G Loss: 1.1576\n",
            "Epoch [73/100], Step [1100/1875], D Loss: 1.2769, G Loss: 0.9630\n",
            "Epoch [73/100], Step [1200/1875], D Loss: 1.2742, G Loss: 1.1109\n",
            "Epoch [73/100], Step [1300/1875], D Loss: 1.1954, G Loss: 0.7494\n",
            "Epoch [73/100], Step [1400/1875], D Loss: 1.2068, G Loss: 1.0720\n",
            "Epoch [73/100], Step [1500/1875], D Loss: 1.2788, G Loss: 1.2797\n",
            "Epoch [73/100], Step [1600/1875], D Loss: 1.0140, G Loss: 1.2286\n",
            "Epoch [73/100], Step [1700/1875], D Loss: 1.1068, G Loss: 1.1746\n",
            "Epoch [73/100], Step [1800/1875], D Loss: 1.1155, G Loss: 1.1711\n",
            "Epoch [74/100], Step [100/1875], D Loss: 1.0847, G Loss: 1.0505\n",
            "Epoch [74/100], Step [200/1875], D Loss: 1.1921, G Loss: 0.9777\n",
            "Epoch [74/100], Step [300/1875], D Loss: 1.1170, G Loss: 1.2240\n",
            "Epoch [74/100], Step [400/1875], D Loss: 1.2804, G Loss: 0.9794\n",
            "Epoch [74/100], Step [500/1875], D Loss: 1.2280, G Loss: 0.9870\n",
            "Epoch [74/100], Step [600/1875], D Loss: 1.1796, G Loss: 1.1074\n",
            "Epoch [74/100], Step [700/1875], D Loss: 1.2952, G Loss: 1.0352\n",
            "Epoch [74/100], Step [800/1875], D Loss: 1.2556, G Loss: 0.9444\n",
            "Epoch [74/100], Step [900/1875], D Loss: 1.2219, G Loss: 1.1351\n",
            "Epoch [74/100], Step [1000/1875], D Loss: 1.0246, G Loss: 1.3649\n",
            "Epoch [74/100], Step [1100/1875], D Loss: 1.1174, G Loss: 1.1368\n",
            "Epoch [74/100], Step [1200/1875], D Loss: 1.3470, G Loss: 1.4297\n",
            "Epoch [74/100], Step [1300/1875], D Loss: 1.0790, G Loss: 1.0127\n",
            "Epoch [74/100], Step [1400/1875], D Loss: 1.2853, G Loss: 0.7648\n",
            "Epoch [74/100], Step [1500/1875], D Loss: 1.3404, G Loss: 0.8820\n",
            "Epoch [74/100], Step [1600/1875], D Loss: 1.2175, G Loss: 0.9314\n",
            "Epoch [74/100], Step [1700/1875], D Loss: 1.1150, G Loss: 0.9779\n",
            "Epoch [74/100], Step [1800/1875], D Loss: 1.1867, G Loss: 0.9656\n",
            "Epoch [75/100], Step [100/1875], D Loss: 1.2642, G Loss: 0.8526\n",
            "Epoch [75/100], Step [200/1875], D Loss: 1.0623, G Loss: 1.0906\n",
            "Epoch [75/100], Step [300/1875], D Loss: 1.2002, G Loss: 1.2324\n",
            "Epoch [75/100], Step [400/1875], D Loss: 1.2105, G Loss: 1.1007\n",
            "Epoch [75/100], Step [500/1875], D Loss: 1.0899, G Loss: 1.0888\n",
            "Epoch [75/100], Step [600/1875], D Loss: 1.0413, G Loss: 1.0450\n",
            "Epoch [75/100], Step [700/1875], D Loss: 1.1198, G Loss: 1.2922\n",
            "Epoch [75/100], Step [800/1875], D Loss: 1.3277, G Loss: 0.8206\n",
            "Epoch [75/100], Step [900/1875], D Loss: 1.1426, G Loss: 1.0054\n",
            "Epoch [75/100], Step [1000/1875], D Loss: 1.2921, G Loss: 1.0341\n",
            "Epoch [75/100], Step [1100/1875], D Loss: 1.0696, G Loss: 1.1041\n",
            "Epoch [75/100], Step [1200/1875], D Loss: 1.3197, G Loss: 1.1827\n",
            "Epoch [75/100], Step [1300/1875], D Loss: 0.9922, G Loss: 1.3130\n",
            "Epoch [75/100], Step [1400/1875], D Loss: 1.1338, G Loss: 1.0864\n",
            "Epoch [75/100], Step [1500/1875], D Loss: 1.3006, G Loss: 0.8551\n",
            "Epoch [75/100], Step [1600/1875], D Loss: 1.2496, G Loss: 0.8194\n",
            "Epoch [75/100], Step [1700/1875], D Loss: 1.2081, G Loss: 1.0421\n",
            "Epoch [75/100], Step [1800/1875], D Loss: 1.0911, G Loss: 0.9743\n",
            "Epoch [76/100], Step [100/1875], D Loss: 1.0652, G Loss: 1.0097\n",
            "Epoch [76/100], Step [200/1875], D Loss: 1.4068, G Loss: 1.0715\n",
            "Epoch [76/100], Step [300/1875], D Loss: 1.3980, G Loss: 1.0026\n",
            "Epoch [76/100], Step [400/1875], D Loss: 1.1932, G Loss: 0.7910\n",
            "Epoch [76/100], Step [500/1875], D Loss: 1.1826, G Loss: 1.4311\n",
            "Epoch [76/100], Step [600/1875], D Loss: 1.3516, G Loss: 0.8878\n",
            "Epoch [76/100], Step [700/1875], D Loss: 0.9412, G Loss: 0.8260\n",
            "Epoch [76/100], Step [800/1875], D Loss: 1.2668, G Loss: 0.8888\n",
            "Epoch [76/100], Step [900/1875], D Loss: 1.3049, G Loss: 1.0585\n",
            "Epoch [76/100], Step [1000/1875], D Loss: 1.1374, G Loss: 1.1001\n",
            "Epoch [76/100], Step [1100/1875], D Loss: 1.2319, G Loss: 1.0811\n",
            "Epoch [76/100], Step [1200/1875], D Loss: 1.3279, G Loss: 0.9954\n",
            "Epoch [76/100], Step [1300/1875], D Loss: 0.9949, G Loss: 1.2043\n",
            "Epoch [76/100], Step [1400/1875], D Loss: 1.3359, G Loss: 0.8387\n",
            "Epoch [76/100], Step [1500/1875], D Loss: 1.2485, G Loss: 0.9625\n",
            "Epoch [76/100], Step [1600/1875], D Loss: 1.1866, G Loss: 0.9251\n",
            "Epoch [76/100], Step [1700/1875], D Loss: 1.1134, G Loss: 1.0582\n",
            "Epoch [76/100], Step [1800/1875], D Loss: 1.2300, G Loss: 1.0348\n",
            "Epoch [77/100], Step [100/1875], D Loss: 1.2081, G Loss: 0.9545\n",
            "Epoch [77/100], Step [200/1875], D Loss: 1.3282, G Loss: 0.8166\n",
            "Epoch [77/100], Step [300/1875], D Loss: 1.2746, G Loss: 0.8488\n",
            "Epoch [77/100], Step [400/1875], D Loss: 1.2967, G Loss: 1.2120\n",
            "Epoch [77/100], Step [500/1875], D Loss: 1.1568, G Loss: 1.0983\n",
            "Epoch [77/100], Step [600/1875], D Loss: 1.0683, G Loss: 1.0024\n",
            "Epoch [77/100], Step [700/1875], D Loss: 1.1174, G Loss: 1.0106\n",
            "Epoch [77/100], Step [800/1875], D Loss: 1.2232, G Loss: 1.4137\n",
            "Epoch [77/100], Step [900/1875], D Loss: 1.4391, G Loss: 0.7865\n",
            "Epoch [77/100], Step [1000/1875], D Loss: 1.3005, G Loss: 0.9373\n",
            "Epoch [77/100], Step [1100/1875], D Loss: 1.0751, G Loss: 1.5386\n",
            "Epoch [77/100], Step [1200/1875], D Loss: 1.0775, G Loss: 1.0903\n",
            "Epoch [77/100], Step [1300/1875], D Loss: 1.0325, G Loss: 1.1347\n",
            "Epoch [77/100], Step [1400/1875], D Loss: 1.0527, G Loss: 1.1875\n",
            "Epoch [77/100], Step [1500/1875], D Loss: 1.0134, G Loss: 1.0295\n",
            "Epoch [77/100], Step [1600/1875], D Loss: 1.1185, G Loss: 1.1724\n",
            "Epoch [77/100], Step [1700/1875], D Loss: 1.1076, G Loss: 1.2796\n",
            "Epoch [77/100], Step [1800/1875], D Loss: 1.3168, G Loss: 0.8879\n",
            "Epoch [78/100], Step [100/1875], D Loss: 1.2759, G Loss: 1.0763\n",
            "Epoch [78/100], Step [200/1875], D Loss: 1.3107, G Loss: 1.0478\n",
            "Epoch [78/100], Step [300/1875], D Loss: 1.1095, G Loss: 1.0003\n",
            "Epoch [78/100], Step [400/1875], D Loss: 0.9913, G Loss: 1.1628\n",
            "Epoch [78/100], Step [500/1875], D Loss: 1.1762, G Loss: 1.2258\n",
            "Epoch [78/100], Step [600/1875], D Loss: 1.2366, G Loss: 1.0314\n",
            "Epoch [78/100], Step [700/1875], D Loss: 1.1453, G Loss: 1.3427\n",
            "Epoch [78/100], Step [800/1875], D Loss: 1.2366, G Loss: 0.8377\n",
            "Epoch [78/100], Step [900/1875], D Loss: 1.1026, G Loss: 1.0386\n",
            "Epoch [78/100], Step [1000/1875], D Loss: 1.1377, G Loss: 1.1176\n",
            "Epoch [78/100], Step [1100/1875], D Loss: 1.1917, G Loss: 1.1499\n",
            "Epoch [78/100], Step [1200/1875], D Loss: 1.5166, G Loss: 0.7528\n",
            "Epoch [78/100], Step [1300/1875], D Loss: 1.2240, G Loss: 1.0353\n",
            "Epoch [78/100], Step [1400/1875], D Loss: 1.0336, G Loss: 1.1394\n",
            "Epoch [78/100], Step [1500/1875], D Loss: 1.1770, G Loss: 1.1257\n",
            "Epoch [78/100], Step [1600/1875], D Loss: 1.1143, G Loss: 1.1300\n",
            "Epoch [78/100], Step [1700/1875], D Loss: 1.1292, G Loss: 1.1905\n",
            "Epoch [78/100], Step [1800/1875], D Loss: 1.1879, G Loss: 0.9317\n",
            "Epoch [79/100], Step [100/1875], D Loss: 1.1675, G Loss: 1.1299\n",
            "Epoch [79/100], Step [200/1875], D Loss: 1.0227, G Loss: 1.0061\n",
            "Epoch [79/100], Step [300/1875], D Loss: 1.1889, G Loss: 0.8828\n",
            "Epoch [79/100], Step [400/1875], D Loss: 1.1274, G Loss: 1.0880\n",
            "Epoch [79/100], Step [500/1875], D Loss: 1.0264, G Loss: 1.0481\n",
            "Epoch [79/100], Step [600/1875], D Loss: 1.2840, G Loss: 0.9040\n",
            "Epoch [79/100], Step [700/1875], D Loss: 1.1562, G Loss: 1.2230\n",
            "Epoch [79/100], Step [800/1875], D Loss: 1.3225, G Loss: 0.9783\n",
            "Epoch [79/100], Step [900/1875], D Loss: 1.3403, G Loss: 0.9657\n",
            "Epoch [79/100], Step [1000/1875], D Loss: 0.9268, G Loss: 1.0950\n",
            "Epoch [79/100], Step [1100/1875], D Loss: 1.2370, G Loss: 0.7865\n",
            "Epoch [79/100], Step [1200/1875], D Loss: 1.0607, G Loss: 0.9637\n",
            "Epoch [79/100], Step [1300/1875], D Loss: 1.2101, G Loss: 1.0072\n",
            "Epoch [79/100], Step [1400/1875], D Loss: 1.2610, G Loss: 1.0954\n",
            "Epoch [79/100], Step [1500/1875], D Loss: 1.0979, G Loss: 1.2273\n",
            "Epoch [79/100], Step [1600/1875], D Loss: 1.2747, G Loss: 1.1194\n",
            "Epoch [79/100], Step [1700/1875], D Loss: 1.1885, G Loss: 0.8885\n",
            "Epoch [79/100], Step [1800/1875], D Loss: 1.2542, G Loss: 1.0741\n",
            "Epoch [80/100], Step [100/1875], D Loss: 1.1119, G Loss: 0.9645\n",
            "Epoch [80/100], Step [200/1875], D Loss: 0.9597, G Loss: 1.1344\n",
            "Epoch [80/100], Step [300/1875], D Loss: 1.2618, G Loss: 1.0016\n",
            "Epoch [80/100], Step [400/1875], D Loss: 1.0011, G Loss: 1.0363\n",
            "Epoch [80/100], Step [500/1875], D Loss: 1.1276, G Loss: 1.1885\n",
            "Epoch [80/100], Step [600/1875], D Loss: 1.2582, G Loss: 1.0214\n",
            "Epoch [80/100], Step [700/1875], D Loss: 1.2458, G Loss: 0.7643\n",
            "Epoch [80/100], Step [800/1875], D Loss: 1.1262, G Loss: 1.1523\n",
            "Epoch [80/100], Step [900/1875], D Loss: 1.2982, G Loss: 0.9332\n",
            "Epoch [80/100], Step [1000/1875], D Loss: 1.2276, G Loss: 0.8360\n",
            "Epoch [80/100], Step [1100/1875], D Loss: 1.3294, G Loss: 0.9481\n",
            "Epoch [80/100], Step [1200/1875], D Loss: 1.2524, G Loss: 0.9101\n",
            "Epoch [80/100], Step [1300/1875], D Loss: 1.1811, G Loss: 1.1216\n",
            "Epoch [80/100], Step [1400/1875], D Loss: 1.1409, G Loss: 1.3214\n",
            "Epoch [80/100], Step [1500/1875], D Loss: 1.1359, G Loss: 0.9740\n",
            "Epoch [80/100], Step [1600/1875], D Loss: 1.1178, G Loss: 1.1830\n",
            "Epoch [80/100], Step [1700/1875], D Loss: 1.0787, G Loss: 1.3089\n",
            "Epoch [80/100], Step [1800/1875], D Loss: 1.2354, G Loss: 1.0824\n",
            "Epoch [81/100], Step [100/1875], D Loss: 1.0334, G Loss: 1.0832\n",
            "Epoch [81/100], Step [200/1875], D Loss: 1.0313, G Loss: 1.1049\n",
            "Epoch [81/100], Step [300/1875], D Loss: 1.1254, G Loss: 0.8818\n",
            "Epoch [81/100], Step [400/1875], D Loss: 1.2929, G Loss: 1.0751\n",
            "Epoch [81/100], Step [500/1875], D Loss: 1.1528, G Loss: 1.1019\n",
            "Epoch [81/100], Step [600/1875], D Loss: 1.2720, G Loss: 0.9543\n",
            "Epoch [81/100], Step [700/1875], D Loss: 1.3877, G Loss: 0.8545\n",
            "Epoch [81/100], Step [800/1875], D Loss: 1.4235, G Loss: 0.9277\n",
            "Epoch [81/100], Step [900/1875], D Loss: 1.2756, G Loss: 0.9356\n",
            "Epoch [81/100], Step [1000/1875], D Loss: 1.1832, G Loss: 0.9882\n",
            "Epoch [81/100], Step [1100/1875], D Loss: 1.3431, G Loss: 0.8942\n",
            "Epoch [81/100], Step [1200/1875], D Loss: 1.1631, G Loss: 1.0630\n",
            "Epoch [81/100], Step [1300/1875], D Loss: 1.0883, G Loss: 1.3751\n",
            "Epoch [81/100], Step [1400/1875], D Loss: 1.1706, G Loss: 0.9637\n",
            "Epoch [81/100], Step [1500/1875], D Loss: 1.1233, G Loss: 0.8555\n",
            "Epoch [81/100], Step [1600/1875], D Loss: 1.0197, G Loss: 1.2117\n",
            "Epoch [81/100], Step [1700/1875], D Loss: 1.2605, G Loss: 1.0340\n",
            "Epoch [81/100], Step [1800/1875], D Loss: 1.2110, G Loss: 1.2766\n",
            "Epoch [82/100], Step [100/1875], D Loss: 1.2068, G Loss: 1.3461\n",
            "Epoch [82/100], Step [200/1875], D Loss: 1.2754, G Loss: 1.0980\n",
            "Epoch [82/100], Step [300/1875], D Loss: 1.0353, G Loss: 1.0778\n",
            "Epoch [82/100], Step [400/1875], D Loss: 0.9851, G Loss: 1.2921\n",
            "Epoch [82/100], Step [500/1875], D Loss: 1.2082, G Loss: 0.9869\n",
            "Epoch [82/100], Step [600/1875], D Loss: 1.1737, G Loss: 1.2667\n",
            "Epoch [82/100], Step [700/1875], D Loss: 1.2676, G Loss: 1.0494\n",
            "Epoch [82/100], Step [800/1875], D Loss: 1.4436, G Loss: 0.8085\n",
            "Epoch [82/100], Step [900/1875], D Loss: 1.1982, G Loss: 0.9333\n",
            "Epoch [82/100], Step [1000/1875], D Loss: 1.2174, G Loss: 0.9618\n",
            "Epoch [82/100], Step [1100/1875], D Loss: 1.2130, G Loss: 1.0614\n",
            "Epoch [82/100], Step [1200/1875], D Loss: 1.1491, G Loss: 0.9550\n",
            "Epoch [82/100], Step [1300/1875], D Loss: 1.1533, G Loss: 1.0398\n",
            "Epoch [82/100], Step [1400/1875], D Loss: 1.1319, G Loss: 1.1519\n",
            "Epoch [82/100], Step [1500/1875], D Loss: 1.1245, G Loss: 1.0989\n",
            "Epoch [82/100], Step [1600/1875], D Loss: 1.1665, G Loss: 0.9431\n",
            "Epoch [82/100], Step [1700/1875], D Loss: 1.1287, G Loss: 1.4316\n",
            "Epoch [82/100], Step [1800/1875], D Loss: 1.1509, G Loss: 1.2356\n",
            "Epoch [83/100], Step [100/1875], D Loss: 1.2331, G Loss: 0.9562\n",
            "Epoch [83/100], Step [200/1875], D Loss: 1.1372, G Loss: 1.1804\n",
            "Epoch [83/100], Step [300/1875], D Loss: 1.0940, G Loss: 1.0487\n",
            "Epoch [83/100], Step [400/1875], D Loss: 1.1135, G Loss: 1.3395\n",
            "Epoch [83/100], Step [500/1875], D Loss: 1.2877, G Loss: 0.8191\n",
            "Epoch [83/100], Step [600/1875], D Loss: 1.1873, G Loss: 0.8871\n",
            "Epoch [83/100], Step [700/1875], D Loss: 1.1379, G Loss: 0.8719\n",
            "Epoch [83/100], Step [800/1875], D Loss: 1.2212, G Loss: 1.1172\n",
            "Epoch [83/100], Step [900/1875], D Loss: 1.1817, G Loss: 1.1815\n",
            "Epoch [83/100], Step [1000/1875], D Loss: 1.1717, G Loss: 1.1482\n",
            "Epoch [83/100], Step [1100/1875], D Loss: 1.2559, G Loss: 1.0568\n",
            "Epoch [83/100], Step [1200/1875], D Loss: 1.4739, G Loss: 1.0720\n",
            "Epoch [83/100], Step [1300/1875], D Loss: 1.3401, G Loss: 1.0672\n",
            "Epoch [83/100], Step [1400/1875], D Loss: 1.3009, G Loss: 0.7935\n",
            "Epoch [83/100], Step [1500/1875], D Loss: 1.2498, G Loss: 0.9601\n",
            "Epoch [83/100], Step [1600/1875], D Loss: 1.2660, G Loss: 0.8391\n",
            "Epoch [83/100], Step [1700/1875], D Loss: 1.2198, G Loss: 1.1029\n",
            "Epoch [83/100], Step [1800/1875], D Loss: 1.1176, G Loss: 1.0245\n",
            "Epoch [84/100], Step [100/1875], D Loss: 1.2071, G Loss: 1.0699\n",
            "Epoch [84/100], Step [200/1875], D Loss: 1.3636, G Loss: 0.9951\n",
            "Epoch [84/100], Step [300/1875], D Loss: 1.2857, G Loss: 0.8430\n",
            "Epoch [84/100], Step [400/1875], D Loss: 1.1687, G Loss: 1.0981\n",
            "Epoch [84/100], Step [500/1875], D Loss: 1.2332, G Loss: 1.0631\n",
            "Epoch [84/100], Step [600/1875], D Loss: 1.1857, G Loss: 1.2327\n",
            "Epoch [84/100], Step [700/1875], D Loss: 1.1886, G Loss: 1.0238\n",
            "Epoch [84/100], Step [800/1875], D Loss: 1.3127, G Loss: 1.0673\n",
            "Epoch [84/100], Step [900/1875], D Loss: 1.0724, G Loss: 1.2186\n",
            "Epoch [84/100], Step [1000/1875], D Loss: 1.3322, G Loss: 0.7083\n",
            "Epoch [84/100], Step [1100/1875], D Loss: 1.3398, G Loss: 1.0342\n",
            "Epoch [84/100], Step [1200/1875], D Loss: 1.2743, G Loss: 1.0004\n",
            "Epoch [84/100], Step [1300/1875], D Loss: 1.0200, G Loss: 1.1047\n",
            "Epoch [84/100], Step [1400/1875], D Loss: 1.2389, G Loss: 1.2271\n",
            "Epoch [84/100], Step [1500/1875], D Loss: 1.2263, G Loss: 1.0481\n",
            "Epoch [84/100], Step [1600/1875], D Loss: 1.0451, G Loss: 1.1203\n",
            "Epoch [84/100], Step [1700/1875], D Loss: 0.9345, G Loss: 1.2675\n",
            "Epoch [84/100], Step [1800/1875], D Loss: 1.0955, G Loss: 0.9706\n",
            "Epoch [85/100], Step [100/1875], D Loss: 1.0291, G Loss: 1.1536\n",
            "Epoch [85/100], Step [200/1875], D Loss: 1.2374, G Loss: 0.9272\n",
            "Epoch [85/100], Step [300/1875], D Loss: 1.2272, G Loss: 1.0559\n",
            "Epoch [85/100], Step [400/1875], D Loss: 1.2255, G Loss: 1.1699\n",
            "Epoch [85/100], Step [500/1875], D Loss: 1.1283, G Loss: 1.1456\n",
            "Epoch [85/100], Step [600/1875], D Loss: 1.1595, G Loss: 1.0059\n",
            "Epoch [85/100], Step [700/1875], D Loss: 1.3113, G Loss: 1.1990\n",
            "Epoch [85/100], Step [800/1875], D Loss: 1.2487, G Loss: 1.0514\n",
            "Epoch [85/100], Step [900/1875], D Loss: 1.3496, G Loss: 0.9596\n",
            "Epoch [85/100], Step [1000/1875], D Loss: 1.3256, G Loss: 0.9894\n",
            "Epoch [85/100], Step [1100/1875], D Loss: 1.1988, G Loss: 0.9523\n",
            "Epoch [85/100], Step [1200/1875], D Loss: 1.0921, G Loss: 1.3082\n",
            "Epoch [85/100], Step [1300/1875], D Loss: 1.0670, G Loss: 1.0379\n",
            "Epoch [85/100], Step [1400/1875], D Loss: 1.2736, G Loss: 0.9125\n",
            "Epoch [85/100], Step [1500/1875], D Loss: 1.4898, G Loss: 0.8834\n",
            "Epoch [85/100], Step [1600/1875], D Loss: 1.1447, G Loss: 1.0894\n",
            "Epoch [85/100], Step [1700/1875], D Loss: 1.1906, G Loss: 1.0162\n",
            "Epoch [85/100], Step [1800/1875], D Loss: 1.5582, G Loss: 1.0973\n",
            "Epoch [86/100], Step [100/1875], D Loss: 1.1687, G Loss: 0.9685\n",
            "Epoch [86/100], Step [200/1875], D Loss: 1.1474, G Loss: 1.4205\n",
            "Epoch [86/100], Step [300/1875], D Loss: 1.1458, G Loss: 0.9333\n",
            "Epoch [86/100], Step [400/1875], D Loss: 1.2031, G Loss: 1.0693\n",
            "Epoch [86/100], Step [500/1875], D Loss: 1.0036, G Loss: 1.0338\n",
            "Epoch [86/100], Step [600/1875], D Loss: 0.9897, G Loss: 1.0971\n",
            "Epoch [86/100], Step [700/1875], D Loss: 1.1416, G Loss: 0.8484\n",
            "Epoch [86/100], Step [800/1875], D Loss: 1.3120, G Loss: 0.9162\n",
            "Epoch [86/100], Step [900/1875], D Loss: 1.0086, G Loss: 1.1691\n",
            "Epoch [86/100], Step [1000/1875], D Loss: 1.1114, G Loss: 1.0879\n",
            "Epoch [86/100], Step [1100/1875], D Loss: 1.0815, G Loss: 0.8926\n",
            "Epoch [86/100], Step [1200/1875], D Loss: 1.0620, G Loss: 1.1148\n",
            "Epoch [86/100], Step [1300/1875], D Loss: 1.3686, G Loss: 1.0043\n",
            "Epoch [86/100], Step [1400/1875], D Loss: 1.3762, G Loss: 0.7673\n",
            "Epoch [86/100], Step [1500/1875], D Loss: 1.2044, G Loss: 0.8818\n",
            "Epoch [86/100], Step [1600/1875], D Loss: 1.3539, G Loss: 1.0254\n",
            "Epoch [86/100], Step [1700/1875], D Loss: 1.1171, G Loss: 1.1446\n",
            "Epoch [86/100], Step [1800/1875], D Loss: 1.1088, G Loss: 1.0041\n",
            "Epoch [87/100], Step [100/1875], D Loss: 1.1576, G Loss: 0.9761\n",
            "Epoch [87/100], Step [200/1875], D Loss: 1.2530, G Loss: 1.1422\n",
            "Epoch [87/100], Step [300/1875], D Loss: 1.1435, G Loss: 0.9148\n",
            "Epoch [87/100], Step [400/1875], D Loss: 0.9868, G Loss: 1.0756\n",
            "Epoch [87/100], Step [500/1875], D Loss: 1.1493, G Loss: 1.1150\n",
            "Epoch [87/100], Step [600/1875], D Loss: 1.0104, G Loss: 1.3301\n",
            "Epoch [87/100], Step [700/1875], D Loss: 1.2484, G Loss: 1.0456\n",
            "Epoch [87/100], Step [800/1875], D Loss: 1.1075, G Loss: 1.1095\n",
            "Epoch [87/100], Step [900/1875], D Loss: 1.1439, G Loss: 1.0314\n",
            "Epoch [87/100], Step [1000/1875], D Loss: 1.4101, G Loss: 0.8806\n",
            "Epoch [87/100], Step [1100/1875], D Loss: 1.2518, G Loss: 0.8172\n",
            "Epoch [87/100], Step [1200/1875], D Loss: 1.1981, G Loss: 1.0675\n",
            "Epoch [87/100], Step [1300/1875], D Loss: 1.1190, G Loss: 1.2340\n",
            "Epoch [87/100], Step [1400/1875], D Loss: 1.1704, G Loss: 1.1592\n",
            "Epoch [87/100], Step [1500/1875], D Loss: 1.2152, G Loss: 0.9819\n",
            "Epoch [87/100], Step [1600/1875], D Loss: 1.2415, G Loss: 1.0811\n",
            "Epoch [87/100], Step [1700/1875], D Loss: 1.1486, G Loss: 0.8900\n",
            "Epoch [87/100], Step [1800/1875], D Loss: 1.1646, G Loss: 0.8224\n",
            "Epoch [88/100], Step [100/1875], D Loss: 1.2691, G Loss: 0.8608\n",
            "Epoch [88/100], Step [200/1875], D Loss: 1.2773, G Loss: 0.9640\n",
            "Epoch [88/100], Step [300/1875], D Loss: 1.3250, G Loss: 0.8769\n",
            "Epoch [88/100], Step [400/1875], D Loss: 1.2859, G Loss: 1.0404\n",
            "Epoch [88/100], Step [500/1875], D Loss: 1.2908, G Loss: 0.8852\n",
            "Epoch [88/100], Step [600/1875], D Loss: 1.4254, G Loss: 0.9108\n",
            "Epoch [88/100], Step [700/1875], D Loss: 1.0136, G Loss: 1.0924\n",
            "Epoch [88/100], Step [800/1875], D Loss: 1.0814, G Loss: 1.1678\n",
            "Epoch [88/100], Step [900/1875], D Loss: 1.2003, G Loss: 1.0740\n",
            "Epoch [88/100], Step [1000/1875], D Loss: 1.1453, G Loss: 0.9402\n",
            "Epoch [88/100], Step [1100/1875], D Loss: 1.1691, G Loss: 0.9360\n",
            "Epoch [88/100], Step [1200/1875], D Loss: 1.1033, G Loss: 1.1092\n",
            "Epoch [88/100], Step [1300/1875], D Loss: 1.1202, G Loss: 1.0868\n",
            "Epoch [88/100], Step [1400/1875], D Loss: 1.2833, G Loss: 0.9416\n",
            "Epoch [88/100], Step [1500/1875], D Loss: 1.1708, G Loss: 0.9966\n",
            "Epoch [88/100], Step [1600/1875], D Loss: 1.1942, G Loss: 0.9230\n",
            "Epoch [88/100], Step [1700/1875], D Loss: 1.1340, G Loss: 1.0139\n",
            "Epoch [88/100], Step [1800/1875], D Loss: 1.2488, G Loss: 1.1210\n",
            "Epoch [89/100], Step [100/1875], D Loss: 1.2278, G Loss: 0.8410\n",
            "Epoch [89/100], Step [200/1875], D Loss: 1.1836, G Loss: 1.2373\n",
            "Epoch [89/100], Step [300/1875], D Loss: 1.1495, G Loss: 1.1001\n",
            "Epoch [89/100], Step [400/1875], D Loss: 1.1603, G Loss: 0.9322\n",
            "Epoch [89/100], Step [500/1875], D Loss: 1.0482, G Loss: 1.0222\n",
            "Epoch [89/100], Step [600/1875], D Loss: 1.2481, G Loss: 0.9860\n",
            "Epoch [89/100], Step [700/1875], D Loss: 1.2218, G Loss: 1.0835\n",
            "Epoch [89/100], Step [800/1875], D Loss: 1.4596, G Loss: 1.1788\n",
            "Epoch [89/100], Step [900/1875], D Loss: 1.2786, G Loss: 1.2358\n",
            "Epoch [89/100], Step [1000/1875], D Loss: 1.4846, G Loss: 1.0314\n",
            "Epoch [89/100], Step [1100/1875], D Loss: 1.1907, G Loss: 1.0183\n",
            "Epoch [89/100], Step [1200/1875], D Loss: 1.0496, G Loss: 1.1280\n",
            "Epoch [89/100], Step [1300/1875], D Loss: 1.2160, G Loss: 0.8784\n",
            "Epoch [89/100], Step [1400/1875], D Loss: 1.4284, G Loss: 0.9189\n",
            "Epoch [89/100], Step [1500/1875], D Loss: 1.1728, G Loss: 1.0450\n",
            "Epoch [89/100], Step [1600/1875], D Loss: 1.2969, G Loss: 1.0239\n",
            "Epoch [89/100], Step [1700/1875], D Loss: 1.4368, G Loss: 0.8054\n",
            "Epoch [89/100], Step [1800/1875], D Loss: 1.0884, G Loss: 0.9365\n",
            "Epoch [90/100], Step [100/1875], D Loss: 1.1736, G Loss: 1.0837\n",
            "Epoch [90/100], Step [200/1875], D Loss: 1.2002, G Loss: 0.9922\n",
            "Epoch [90/100], Step [300/1875], D Loss: 1.1219, G Loss: 1.0325\n",
            "Epoch [90/100], Step [400/1875], D Loss: 1.1490, G Loss: 0.9436\n",
            "Epoch [90/100], Step [500/1875], D Loss: 1.2679, G Loss: 1.0919\n",
            "Epoch [90/100], Step [600/1875], D Loss: 1.1266, G Loss: 0.8719\n",
            "Epoch [90/100], Step [700/1875], D Loss: 1.2839, G Loss: 0.8907\n",
            "Epoch [90/100], Step [800/1875], D Loss: 1.2326, G Loss: 1.1324\n",
            "Epoch [90/100], Step [900/1875], D Loss: 1.2784, G Loss: 0.8122\n",
            "Epoch [90/100], Step [1000/1875], D Loss: 1.1277, G Loss: 1.0073\n",
            "Epoch [90/100], Step [1100/1875], D Loss: 1.1778, G Loss: 1.1618\n",
            "Epoch [90/100], Step [1200/1875], D Loss: 1.0299, G Loss: 1.0290\n",
            "Epoch [90/100], Step [1300/1875], D Loss: 1.1458, G Loss: 1.1544\n",
            "Epoch [90/100], Step [1400/1875], D Loss: 1.1192, G Loss: 1.0969\n",
            "Epoch [90/100], Step [1500/1875], D Loss: 0.9764, G Loss: 1.1641\n",
            "Epoch [90/100], Step [1600/1875], D Loss: 1.3434, G Loss: 0.9327\n",
            "Epoch [90/100], Step [1700/1875], D Loss: 1.3186, G Loss: 1.1461\n",
            "Epoch [90/100], Step [1800/1875], D Loss: 1.1088, G Loss: 1.0530\n",
            "Epoch [91/100], Step [100/1875], D Loss: 1.1820, G Loss: 1.0432\n",
            "Epoch [91/100], Step [200/1875], D Loss: 1.1304, G Loss: 1.1652\n",
            "Epoch [91/100], Step [300/1875], D Loss: 1.3808, G Loss: 0.7733\n",
            "Epoch [91/100], Step [400/1875], D Loss: 1.3158, G Loss: 1.2258\n",
            "Epoch [91/100], Step [500/1875], D Loss: 1.0682, G Loss: 1.0462\n",
            "Epoch [91/100], Step [600/1875], D Loss: 1.2995, G Loss: 1.0003\n",
            "Epoch [91/100], Step [700/1875], D Loss: 1.0975, G Loss: 1.0509\n",
            "Epoch [91/100], Step [800/1875], D Loss: 1.0556, G Loss: 1.0768\n",
            "Epoch [91/100], Step [900/1875], D Loss: 1.2023, G Loss: 1.0046\n",
            "Epoch [91/100], Step [1000/1875], D Loss: 0.9897, G Loss: 1.3266\n",
            "Epoch [91/100], Step [1100/1875], D Loss: 1.1730, G Loss: 0.9103\n",
            "Epoch [91/100], Step [1200/1875], D Loss: 1.2462, G Loss: 1.0382\n",
            "Epoch [91/100], Step [1300/1875], D Loss: 1.2492, G Loss: 0.8467\n",
            "Epoch [91/100], Step [1400/1875], D Loss: 1.2897, G Loss: 1.0588\n",
            "Epoch [91/100], Step [1500/1875], D Loss: 1.1272, G Loss: 0.9495\n",
            "Epoch [91/100], Step [1600/1875], D Loss: 1.1852, G Loss: 1.0142\n",
            "Epoch [91/100], Step [1700/1875], D Loss: 1.1569, G Loss: 1.0487\n",
            "Epoch [91/100], Step [1800/1875], D Loss: 1.2395, G Loss: 0.9989\n",
            "Epoch [92/100], Step [100/1875], D Loss: 1.1398, G Loss: 1.0821\n",
            "Epoch [92/100], Step [200/1875], D Loss: 1.2592, G Loss: 0.8357\n",
            "Epoch [92/100], Step [300/1875], D Loss: 1.0648, G Loss: 1.0809\n",
            "Epoch [92/100], Step [400/1875], D Loss: 1.1199, G Loss: 1.0460\n",
            "Epoch [92/100], Step [500/1875], D Loss: 0.9442, G Loss: 1.3521\n",
            "Epoch [92/100], Step [600/1875], D Loss: 1.1544, G Loss: 1.3249\n",
            "Epoch [92/100], Step [700/1875], D Loss: 1.2118, G Loss: 0.9271\n",
            "Epoch [92/100], Step [800/1875], D Loss: 1.2116, G Loss: 1.1338\n",
            "Epoch [92/100], Step [900/1875], D Loss: 1.1314, G Loss: 1.0767\n",
            "Epoch [92/100], Step [1000/1875], D Loss: 1.0356, G Loss: 1.1305\n",
            "Epoch [92/100], Step [1100/1875], D Loss: 1.2982, G Loss: 1.0175\n",
            "Epoch [92/100], Step [1200/1875], D Loss: 1.3369, G Loss: 1.0748\n",
            "Epoch [92/100], Step [1300/1875], D Loss: 1.1837, G Loss: 0.8900\n",
            "Epoch [92/100], Step [1400/1875], D Loss: 1.3811, G Loss: 1.1365\n",
            "Epoch [92/100], Step [1500/1875], D Loss: 1.3396, G Loss: 0.9279\n",
            "Epoch [92/100], Step [1600/1875], D Loss: 1.0545, G Loss: 1.5056\n",
            "Epoch [92/100], Step [1700/1875], D Loss: 1.1376, G Loss: 1.0481\n",
            "Epoch [92/100], Step [1800/1875], D Loss: 1.3567, G Loss: 1.0677\n",
            "Epoch [93/100], Step [100/1875], D Loss: 1.2214, G Loss: 1.1232\n",
            "Epoch [93/100], Step [200/1875], D Loss: 1.1624, G Loss: 0.9612\n",
            "Epoch [93/100], Step [300/1875], D Loss: 1.2407, G Loss: 1.1574\n",
            "Epoch [93/100], Step [400/1875], D Loss: 1.1784, G Loss: 0.8709\n",
            "Epoch [93/100], Step [500/1875], D Loss: 1.0700, G Loss: 1.0099\n",
            "Epoch [93/100], Step [600/1875], D Loss: 1.2814, G Loss: 1.0340\n",
            "Epoch [93/100], Step [700/1875], D Loss: 1.3046, G Loss: 0.9635\n",
            "Epoch [93/100], Step [800/1875], D Loss: 1.3908, G Loss: 1.1734\n",
            "Epoch [93/100], Step [900/1875], D Loss: 1.2707, G Loss: 0.9230\n",
            "Epoch [93/100], Step [1000/1875], D Loss: 1.2455, G Loss: 0.9360\n",
            "Epoch [93/100], Step [1100/1875], D Loss: 1.2172, G Loss: 0.9246\n",
            "Epoch [93/100], Step [1200/1875], D Loss: 1.4265, G Loss: 1.0613\n",
            "Epoch [93/100], Step [1300/1875], D Loss: 1.2816, G Loss: 1.2824\n",
            "Epoch [93/100], Step [1400/1875], D Loss: 1.2701, G Loss: 1.3068\n",
            "Epoch [93/100], Step [1500/1875], D Loss: 1.4096, G Loss: 0.7224\n",
            "Epoch [93/100], Step [1600/1875], D Loss: 1.0932, G Loss: 0.9756\n",
            "Epoch [93/100], Step [1700/1875], D Loss: 1.1405, G Loss: 0.9993\n",
            "Epoch [93/100], Step [1800/1875], D Loss: 1.1609, G Loss: 1.1969\n",
            "Epoch [94/100], Step [100/1875], D Loss: 1.1038, G Loss: 1.1331\n",
            "Epoch [94/100], Step [200/1875], D Loss: 1.1973, G Loss: 1.1569\n",
            "Epoch [94/100], Step [300/1875], D Loss: 0.9975, G Loss: 1.1226\n",
            "Epoch [94/100], Step [400/1875], D Loss: 0.9542, G Loss: 1.3799\n",
            "Epoch [94/100], Step [500/1875], D Loss: 1.1743, G Loss: 0.7604\n",
            "Epoch [94/100], Step [600/1875], D Loss: 1.0916, G Loss: 1.1246\n",
            "Epoch [94/100], Step [700/1875], D Loss: 1.3442, G Loss: 1.1581\n",
            "Epoch [94/100], Step [800/1875], D Loss: 1.0033, G Loss: 1.3453\n",
            "Epoch [94/100], Step [900/1875], D Loss: 1.2366, G Loss: 0.7529\n",
            "Epoch [94/100], Step [1000/1875], D Loss: 1.2264, G Loss: 0.9019\n",
            "Epoch [94/100], Step [1100/1875], D Loss: 1.2363, G Loss: 1.0590\n",
            "Epoch [94/100], Step [1200/1875], D Loss: 1.0564, G Loss: 0.9426\n",
            "Epoch [94/100], Step [1300/1875], D Loss: 1.2152, G Loss: 0.8292\n",
            "Epoch [94/100], Step [1400/1875], D Loss: 1.3762, G Loss: 0.9343\n",
            "Epoch [94/100], Step [1500/1875], D Loss: 1.1264, G Loss: 1.0290\n",
            "Epoch [94/100], Step [1600/1875], D Loss: 1.2542, G Loss: 1.1793\n",
            "Epoch [94/100], Step [1700/1875], D Loss: 1.2015, G Loss: 1.0884\n",
            "Epoch [94/100], Step [1800/1875], D Loss: 1.1010, G Loss: 1.3203\n",
            "Epoch [95/100], Step [100/1875], D Loss: 1.2723, G Loss: 0.9686\n",
            "Epoch [95/100], Step [200/1875], D Loss: 1.1907, G Loss: 0.9678\n",
            "Epoch [95/100], Step [300/1875], D Loss: 1.2061, G Loss: 1.2217\n",
            "Epoch [95/100], Step [400/1875], D Loss: 1.1382, G Loss: 1.0685\n",
            "Epoch [95/100], Step [500/1875], D Loss: 1.2382, G Loss: 0.9477\n",
            "Epoch [95/100], Step [600/1875], D Loss: 1.2403, G Loss: 0.8078\n",
            "Epoch [95/100], Step [700/1875], D Loss: 1.1553, G Loss: 0.9546\n",
            "Epoch [95/100], Step [800/1875], D Loss: 1.0874, G Loss: 0.8947\n",
            "Epoch [95/100], Step [900/1875], D Loss: 1.2120, G Loss: 0.8672\n",
            "Epoch [95/100], Step [1000/1875], D Loss: 1.2354, G Loss: 1.0703\n",
            "Epoch [95/100], Step [1100/1875], D Loss: 1.2703, G Loss: 0.9691\n",
            "Epoch [95/100], Step [1200/1875], D Loss: 1.2460, G Loss: 1.0817\n",
            "Epoch [95/100], Step [1300/1875], D Loss: 1.1912, G Loss: 0.9710\n",
            "Epoch [95/100], Step [1400/1875], D Loss: 1.0717, G Loss: 1.1172\n",
            "Epoch [95/100], Step [1500/1875], D Loss: 1.1506, G Loss: 1.0555\n",
            "Epoch [95/100], Step [1600/1875], D Loss: 1.3168, G Loss: 0.9643\n",
            "Epoch [95/100], Step [1700/1875], D Loss: 1.2906, G Loss: 1.0471\n",
            "Epoch [95/100], Step [1800/1875], D Loss: 1.2692, G Loss: 0.9015\n",
            "Epoch [96/100], Step [100/1875], D Loss: 1.2936, G Loss: 1.0957\n",
            "Epoch [96/100], Step [200/1875], D Loss: 1.2946, G Loss: 0.8574\n",
            "Epoch [96/100], Step [300/1875], D Loss: 1.0913, G Loss: 1.2644\n",
            "Epoch [96/100], Step [400/1875], D Loss: 1.0608, G Loss: 0.9310\n",
            "Epoch [96/100], Step [500/1875], D Loss: 1.1275, G Loss: 0.9745\n",
            "Epoch [96/100], Step [600/1875], D Loss: 1.1202, G Loss: 1.2476\n",
            "Epoch [96/100], Step [700/1875], D Loss: 1.0743, G Loss: 1.1414\n",
            "Epoch [96/100], Step [800/1875], D Loss: 1.1538, G Loss: 1.1392\n",
            "Epoch [96/100], Step [900/1875], D Loss: 1.1980, G Loss: 1.0756\n",
            "Epoch [96/100], Step [1000/1875], D Loss: 1.3365, G Loss: 0.9649\n",
            "Epoch [96/100], Step [1100/1875], D Loss: 1.3409, G Loss: 1.0383\n",
            "Epoch [96/100], Step [1200/1875], D Loss: 0.9442, G Loss: 1.1846\n",
            "Epoch [96/100], Step [1300/1875], D Loss: 1.1726, G Loss: 1.3849\n",
            "Epoch [96/100], Step [1400/1875], D Loss: 1.1401, G Loss: 1.2607\n",
            "Epoch [96/100], Step [1500/1875], D Loss: 1.1424, G Loss: 1.1605\n",
            "Epoch [96/100], Step [1600/1875], D Loss: 1.2966, G Loss: 1.0666\n",
            "Epoch [96/100], Step [1700/1875], D Loss: 1.0814, G Loss: 0.9564\n",
            "Epoch [96/100], Step [1800/1875], D Loss: 1.1372, G Loss: 1.1817\n",
            "Epoch [97/100], Step [100/1875], D Loss: 1.0440, G Loss: 1.1217\n",
            "Epoch [97/100], Step [200/1875], D Loss: 1.2893, G Loss: 0.9334\n",
            "Epoch [97/100], Step [300/1875], D Loss: 1.0205, G Loss: 1.2191\n",
            "Epoch [97/100], Step [400/1875], D Loss: 1.1937, G Loss: 0.9057\n",
            "Epoch [97/100], Step [500/1875], D Loss: 1.3616, G Loss: 0.9959\n",
            "Epoch [97/100], Step [600/1875], D Loss: 1.2035, G Loss: 0.8337\n",
            "Epoch [97/100], Step [700/1875], D Loss: 1.1702, G Loss: 0.7917\n",
            "Epoch [97/100], Step [800/1875], D Loss: 1.3880, G Loss: 0.7354\n",
            "Epoch [97/100], Step [900/1875], D Loss: 1.0736, G Loss: 1.2943\n",
            "Epoch [97/100], Step [1000/1875], D Loss: 1.1686, G Loss: 0.8934\n",
            "Epoch [97/100], Step [1100/1875], D Loss: 1.3304, G Loss: 0.9621\n",
            "Epoch [97/100], Step [1200/1875], D Loss: 1.2410, G Loss: 1.0951\n",
            "Epoch [97/100], Step [1300/1875], D Loss: 1.0771, G Loss: 1.2629\n",
            "Epoch [97/100], Step [1400/1875], D Loss: 1.2287, G Loss: 0.8318\n",
            "Epoch [97/100], Step [1500/1875], D Loss: 1.3025, G Loss: 1.0611\n",
            "Epoch [97/100], Step [1600/1875], D Loss: 1.2080, G Loss: 0.9168\n",
            "Epoch [97/100], Step [1700/1875], D Loss: 1.2347, G Loss: 1.0243\n",
            "Epoch [97/100], Step [1800/1875], D Loss: 1.2041, G Loss: 1.0042\n",
            "Epoch [98/100], Step [100/1875], D Loss: 1.2368, G Loss: 1.1439\n",
            "Epoch [98/100], Step [200/1875], D Loss: 1.2711, G Loss: 0.8580\n",
            "Epoch [98/100], Step [300/1875], D Loss: 1.2704, G Loss: 1.0039\n",
            "Epoch [98/100], Step [400/1875], D Loss: 1.3452, G Loss: 0.9183\n",
            "Epoch [98/100], Step [500/1875], D Loss: 1.1517, G Loss: 0.9691\n",
            "Epoch [98/100], Step [600/1875], D Loss: 1.1863, G Loss: 1.0390\n",
            "Epoch [98/100], Step [700/1875], D Loss: 1.2755, G Loss: 1.0399\n",
            "Epoch [98/100], Step [800/1875], D Loss: 1.1543, G Loss: 1.2625\n",
            "Epoch [98/100], Step [900/1875], D Loss: 1.3648, G Loss: 0.9112\n",
            "Epoch [98/100], Step [1000/1875], D Loss: 1.2596, G Loss: 1.1860\n",
            "Epoch [98/100], Step [1100/1875], D Loss: 1.2130, G Loss: 1.1120\n",
            "Epoch [98/100], Step [1200/1875], D Loss: 1.2036, G Loss: 0.9229\n",
            "Epoch [98/100], Step [1300/1875], D Loss: 1.1112, G Loss: 1.0244\n",
            "Epoch [98/100], Step [1400/1875], D Loss: 1.2058, G Loss: 0.7796\n",
            "Epoch [98/100], Step [1500/1875], D Loss: 1.2659, G Loss: 1.0304\n",
            "Epoch [98/100], Step [1600/1875], D Loss: 1.1348, G Loss: 1.2353\n",
            "Epoch [98/100], Step [1700/1875], D Loss: 1.1301, G Loss: 1.0854\n",
            "Epoch [98/100], Step [1800/1875], D Loss: 1.1250, G Loss: 1.0568\n",
            "Epoch [99/100], Step [100/1875], D Loss: 1.2911, G Loss: 0.9117\n",
            "Epoch [99/100], Step [200/1875], D Loss: 1.1556, G Loss: 1.1228\n",
            "Epoch [99/100], Step [300/1875], D Loss: 0.9630, G Loss: 0.9616\n",
            "Epoch [99/100], Step [400/1875], D Loss: 0.9806, G Loss: 1.0646\n",
            "Epoch [99/100], Step [500/1875], D Loss: 0.9986, G Loss: 1.2811\n",
            "Epoch [99/100], Step [600/1875], D Loss: 1.2564, G Loss: 1.0212\n",
            "Epoch [99/100], Step [700/1875], D Loss: 1.1827, G Loss: 0.9200\n",
            "Epoch [99/100], Step [800/1875], D Loss: 1.0661, G Loss: 1.3162\n",
            "Epoch [99/100], Step [900/1875], D Loss: 1.3273, G Loss: 0.8399\n",
            "Epoch [99/100], Step [1000/1875], D Loss: 1.1367, G Loss: 0.9923\n",
            "Epoch [99/100], Step [1100/1875], D Loss: 1.1878, G Loss: 0.9378\n",
            "Epoch [99/100], Step [1200/1875], D Loss: 1.1435, G Loss: 1.0072\n",
            "Epoch [99/100], Step [1300/1875], D Loss: 1.0494, G Loss: 1.1679\n",
            "Epoch [99/100], Step [1400/1875], D Loss: 1.1851, G Loss: 0.9904\n",
            "Epoch [99/100], Step [1500/1875], D Loss: 1.3457, G Loss: 1.0731\n",
            "Epoch [99/100], Step [1600/1875], D Loss: 1.1885, G Loss: 1.1095\n",
            "Epoch [99/100], Step [1700/1875], D Loss: 1.1619, G Loss: 0.9771\n",
            "Epoch [99/100], Step [1800/1875], D Loss: 1.2008, G Loss: 1.0670\n",
            "Epoch [100/100], Step [100/1875], D Loss: 1.1904, G Loss: 0.9757\n",
            "Epoch [100/100], Step [200/1875], D Loss: 1.3589, G Loss: 1.0245\n",
            "Epoch [100/100], Step [300/1875], D Loss: 1.1253, G Loss: 0.8418\n",
            "Epoch [100/100], Step [400/1875], D Loss: 1.1620, G Loss: 1.0734\n",
            "Epoch [100/100], Step [500/1875], D Loss: 1.2369, G Loss: 1.0789\n",
            "Epoch [100/100], Step [600/1875], D Loss: 1.1692, G Loss: 1.1297\n",
            "Epoch [100/100], Step [700/1875], D Loss: 1.0459, G Loss: 0.9823\n",
            "Epoch [100/100], Step [800/1875], D Loss: 1.1034, G Loss: 1.2039\n",
            "Epoch [100/100], Step [900/1875], D Loss: 1.1330, G Loss: 1.1226\n",
            "Epoch [100/100], Step [1000/1875], D Loss: 1.3575, G Loss: 0.9207\n",
            "Epoch [100/100], Step [1100/1875], D Loss: 1.2524, G Loss: 1.0242\n",
            "Epoch [100/100], Step [1200/1875], D Loss: 1.1103, G Loss: 1.1158\n",
            "Epoch [100/100], Step [1300/1875], D Loss: 1.1104, G Loss: 1.1895\n",
            "Epoch [100/100], Step [1400/1875], D Loss: 1.2463, G Loss: 1.0665\n",
            "Epoch [100/100], Step [1500/1875], D Loss: 1.2382, G Loss: 1.0991\n",
            "Epoch [100/100], Step [1600/1875], D Loss: 1.3129, G Loss: 0.7310\n",
            "Epoch [100/100], Step [1700/1875], D Loss: 1.2819, G Loss: 0.8817\n",
            "Epoch [100/100], Step [1800/1875], D Loss: 1.1776, G Loss: 0.9016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generación de imágenes\n",
        "#se crea un tensor z que representa 64 vectores de ruido aleatorio, cada uno con dimensión 100. Sirve como input del generador.\n",
        "#y es la semilla para crear imágenes.\n",
        "z = torch.randn(64, 256)\n",
        "\n",
        "\n",
        "#el ruido  z se pasa al generador el cual lo transforma en imágenes de salida, el output tendrá la forma (64,784) debido a la última capa del generador.\n",
        "generated_images = generator(z).view(-1, 1, 28, 28).detach().numpy()\n",
        "\n",
        "#-1 en la primera entrada permite a PyTorch determinar automáticamente el tamaño del primer eje (en este caso, el batch size).\n",
        "#(1, 28, 28) es el tamaño final de cada imagen e indica que es una imagen de un solo canal (blanco y negro) de tamaño 28x28.\n",
        "#detach() evita que las operaciones posteriores afecten al grafo de cómputo de PyTorch, congelando las imágenes generadas en su estado actual.\n",
        "#numpy() convierte el tensor de PyTorch en un arreglo de NumPy para que se pueda visualizar con matplotlib.\n",
        "\n",
        "\n",
        "\n",
        "# Visualización de las imágenes generadas.\n",
        "fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(generated_images[i][0], cmap='gray')\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "2yc2_bdR8Bbd",
        "outputId": "ea036491-914f-41ee-a4fc-61a9d0be3128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5c6b5144e5b9>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#el ruido  z se pasa al generador el cual lo transforma en imágenes de salida, el output tendrá la forma (64,784) debido a la última capa del generador.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#-1 en la primera entrada permite a PyTorch determinar automáticamente el tamaño del primer eje (en este caso, el batch size).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
          ]
        }
      ]
    }
  ]
}